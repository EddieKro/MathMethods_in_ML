{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. –ö–ª–∞—Å–∏—á–Ω–∏–π —Ç–∞ —ñ–º–æ–≤—ñ—Ä–Ω–∏—Å–Ω–∏–π –º–µ—Ç–æ–¥–∏ –≥–æ–ª–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç. –ú–µ—Ç–æ–¥–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –≥–æ–ª–æ–≤–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤.\n",
    "PCA can be defined as a set of methods which goal is to build an orthogonal basis of \"best fitting\" lines which minimize the average squared distance from a point to the line. \n",
    "\n",
    "* Classical PCA: Suppose we want to find an orthogonal set of ùêø linear basis vectors ùê∞_ùëó‚àà‚Ñù^ùê∑, and the corresponding scores ùê≥_ùëñ‚àà‚Ñù^ùêø, such that we minimize the average reconstruction error ùêΩ(ùêñ, ùêô)=1/ùëÅ ‚àë_(ùëñ=1)^ùëÅ‚ñí‚Äñùê±_ùëñ‚àíùê±¬†ÃÇ_ùëñ ‚Äñ^2 <br>\n",
    "where ùê±¬†ÃÇ_ùëñ=ùêñùê≥_ùëñ, subject to the constrain that ùêñ is orthonormal. Equivalently, we can write this objective as follow: $ùêΩ(ùêñ, ùêô)=„Äñ‚Äñùêó‚àíùêñùêô^ùëá ‚Äñ_ùêπ„Äó^2$\n",
    "where ùêô is an ùëÅ√óùêø matrix with the ùê≥_ùëñ in its rows, and $||A||_F$ is the Frobenius norm of matrix ùêÄ, defined by $‚ÄñùêÄ‚Äñ_ùêπ=‚àö(‚àë_(ùëñ=1)^ùëö‚ñí‚àë_(ùëó=1)^ùëõ‚ñí„Äñùëé_ùëñùëó„Äó^2 )=‚àö(ùë°ùëü [ùêÄ^ùëá ùêÄ] )=‚ÄñùêÄ(:)‚Äñ_2$\n",
    "\n",
    "The optimal solution is obtained by setting ùêñ¬†ÃÇ=ùêï_ùêø, where ùêï_ùêø contains the ùêø eigenvectors with the largest eigenvalues of empirical covariance matrix, ùö∫¬†ÃÇ=1/ùëÅ ‚àë_(ùëñ=1)^ùëÅ‚ñí„Äñùê±_ùëñ „Äñùê±_ùëñ„Äó^ùëá „Äó (we assume the ùê±_ùëñ have zeros mean, for notation simplicity). Furthermore, the optimal low-dimensional encoding of data is given by ùê≥¬†ÃÇ_ùëñ=ùêñ^ùëá ùê±_ùëñ, which is an orthogonal projection of the data onto the column space spanned by the eigenvectors.\n",
    "\n",
    "\n",
    "* Probabilistic PCA: Consider a factor analysis model in which ùöø=$\\sigma^2I$ . The observed data log likelihood is given by $ log‚Å°[ùëù(ùêó|ùêñ,ùúé^2 )]=(‚àíùëÅ/2)  ln‚Å°[ùêÇ]‚àí1/2 \\sum_{i=1}^N[„Äñùê±_ùëñ„Äó^ùëá ùêÇ^(‚àí1) ùê±_ùëñ ]=(‚àíùëÅ/2)  ln‚Å°[ùêÇ]+tr[C^{-1} \\sum] $\n",
    "\n",
    "where ùêÇ=ùêñùêñ^ùëá+ùúé^2 ùêà and ùêí=1/ùëÅ ‚àë_(ùëñ=1)^ùëÅ‚ñí„Äñùê±_ùëñ „Äñùê±_ùëñ„Äó^ùëá „Äó=1/ùëÅ ùêó^ùëá ùêó (we are assuming centered data, for notational simplicity). The maxima of the log-likelihood are given by ùêñ¬†ÃÇ=ùêï(ùö≤‚àíùúé^2 ùêà)^(1/2) ùêë, where ùêë is an arbitrary ùêø√óùêø orthogonal matrix, ùêï is the ùê∑√óùêø matrix whose columns are the first ùêø eigenvectors of the ùêí, and ùö≤ is the corresponding diagonal matrix of eigenvalues.\n",
    "\n",
    "the MLE of the noise variance s given by $\\sigma^2=1/(D-L) \\sum_{ùëó=ùêø+1}^D\\lambda_j $\n",
    "\n",
    "* PCA may also be solved via an SVD composition: any real NxD matrix X can be decomposed as $X_{NxD}=U_{NxN}* S_{NxD} * V_{DxD}^T$, where $U$ and $V$ are matrices with orthonormal columns, S - matrix of zeros, containing $r = min(N,D)$ singular values $\\sigma_i>0$ on the main diagonal. Columns of U(V) are left(right) singular vectors\n",
    "\n",
    "* PCA may be solved via EM-algorithm, with: <br>E-step: ùêô¬†ÃÉ=(ùêñ^ùëá ùêñ)^(‚àí1) ùêñ^ùëá ùêó <br>M-step: $W =XZ^T(ZZ^T)^-1 $, where $Z_{LxN}$ stands for a matrix storing the posterior means  along its columns; X~=X^T stores the original data along its columns\n",
    "\n",
    "Some advantages of EM-algo:\n",
    "   *  can be faster\n",
    "   *  can handle missing data in a simple way\n",
    "\n",
    "### 2. –ú–µ—Ç–æ–¥ –Ω–µ–∑–∞–ª–µ–∂–Ω–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç. –ö—Ä–∏—Ç–µ—Ä—ñ—ó –Ω–µ–∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤.\n",
    "ICA(Independent Component Analysis ) - method to separate multivariate sygnal into additive subcomponents without any previous \"knowledge\" about a source of sygnals; special case of blind source separation.\n",
    "We assume that every subcomponent is a non-Gaussian signal and that all of them are statistically independent from each other\n",
    "\n",
    "Criterias to estimate ICA params:\n",
    "* Maximum likelihood estimation: $$NLL(V) = \\sum_{j=1}^L E(G_j(z_j) \\to\\min$$\n",
    "where $V=W^-1$ - recognition weights; $z_j‚âú[ùêØ_ùëó]^ùëáùê±$ and $ùê∫_ùëó(ùëß)‚âú(‚àílog‚Å°[ùëù_ùëó (ùëß)] )$\n",
    "\n",
    "* Maximizing non-Gaussianity ‚Äì kurtosis or neg-entropy:$$negentropy(z) ‚âú H[N(\\mu,\\sigma^2)]-H[z] $$\n",
    "    \n",
    "* Minimizing mutual information: $$I(z)‚âúùïÇùïÉ[ùëù(ùê≥)||\\prod_j ùëù(ùëß_ùëó ) ]=\\sum_j H[z_j] -H[z]$$\n",
    " \n",
    "\n",
    "\n",
    "### 3. –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –º–∞—Ä–∫—ñ–≤—Å—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –≤ –∑–∞–¥–∞—á–∞—Ö –º–æ–¥–µ–ª—é–≤–∞–Ω–Ω—è –ø—Ä–∏—Ä–æ–¥–Ω–∏—Ö –º–æ–≤.\n",
    "–ú–æ–∂–µ–º–æ –∑–º–æ–¥–µ–ª—é–≤–∞—Ç–∏ —Ä–µ—á–µ–Ω–Ω—è —É –≤–∏–≥–ª—è–¥—ñ $P(x_1...x_t) = p(x1)p(x2|x1)p(x3|x1, x2) ... p(xt|x1 ... xt-1)$. –ù–∞–º –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–Ω–∞–π—Ç–∏ –Ω–∞–π–±—ñ–ª—å—à –π–º–æ–≤—ñ—Ä–Ω—É –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å —Ç–µ–≥—ñ–≤ –∑–∞ –¥–∞–Ω–æ–≥–æ —Ä–µ—á–µ–Ω–Ω—è. $—É = argmax P(y|x) = argmax p(x, y)$ –¥–µ $P(x, y) = P(x|y)P(y) = Product from t=1 to T P(x_t|y_t)P(y_t|y_t-1)$ –∑–∞ —É–º–æ–≤–∏ –ú–∞—Ä–∫—ñ–≤—Å—å–∫–æ–≥–æ –ø—Ä–∏–ø—É—â–µ–Ω–Ω—è $p(y) = product from t=1 to T P(y_t|y_t-1)$\n",
    "\n",
    "### 4. –£–º–æ–≤–∏ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è —Å—Ç–∞—Ü—ñ–æ–Ω–∞—Ä–Ω–æ–≥–æ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –¥–ª—è –º–∞—Ä–∫—ñ–≤—Å—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "\n",
    "–ú–∞—é—Ç—å –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏—Å—è 2 —É–º–æ–≤–∏:<br>\n",
    "\n",
    "* Theorem: Every irreducible (singly connected), aperiodic finite state Markov chain has a limiting distribution, which is equal to pi, its unique stationary distribution.(–ö–æ–∂–Ω–∏–π –Ω–µ–ø—Ä–∏–≤—ñ–¥–Ω–∏–π –∞–ø–µ—Ä—ñ–æ–¥–∏—á–Ω–∏–π –ª–∞–Ω—Ü—é–≥ –ú–∞—Ä–∫–æ–≤–∞ –∑ –∫—ñ–Ω—Ü–µ–≤–æ—é –∫-—Ç—é —Å—Ç–∞–Ω—ñ–≤ –º–∞—î –æ–±–º–µ–∂—É—é—á–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª,—â–æ —Å–ø—ñ–≤–ø–∞–¥–∞—î –∑ –¥–µ—è–∫–∏–º —Ä–æ–∑–ø–æ–¥—ñ–ª–æ–º pi , –π–æ–≥–æ —î–¥–∏–Ω–∏–º —Å—Ç–∞—Ü. —Ä–æ–∑–ø–æ–¥—ñ–ª–æ–º)<br>\n",
    "* Theorem: Every irreducible (singly connected), ergodic Markov chain has a limiting distribution, which is equal to pi, its unique stationary distribution.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. –ú–µ—Ç–æ–¥–∏ –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å (inference) –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏—Ö –º–∞—Ä–∫—ñ–≤—Å—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π.\n",
    "L5, slide 15<br>\n",
    "–§—ñ–ª—å—Ç—Ä—É–≤–∞–Ω–Ω—è(filtering), –∑–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è –∑ —Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–º –ª–∞–≥–æ–º(fixed lag smoothing), –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è(prediction),\n",
    "–æ—Ü—ñ–Ω–∫–∞ –∞–ø–æ—Å—Ç–µ—Ä—ñ–æ—Ä–Ω–æ–≥–æ –º–∞–∫—Å–∏–º—É–º—É(MAP estimation), 'Probability of the evidence'.\n",
    "\n",
    "\n",
    "### 6. –†–æ–±–∞—Å—Ç–Ω–∞ —Ç–∞ –≥—Ä–µ–±–Ω–µ–≤–∞ (ridge) —Ä–µ–≥—Ä–µ—Å—ñ—è. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ –ª—ñ–Ω—ñ–π–Ω–æ—é —Ä–µ–≥—Ä–µ—Å—ñ—î—é.\n",
    "\n",
    "\n",
    "\n",
    "### 7. –í–∏–≤–µ–¥–µ–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è–Ω–Ω—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó.\n",
    "\n",
    "\n",
    "\n",
    "### 8. –ü–æ–Ω—è—Ç—Ç—è —è–¥–µ—Ä–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π. –í–∏–º–æ–≥–∏ –¥–æ —è–¥–µ—Ä–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π (—Ç–µ–æ—Ä–µ–º–∞ –ú–µ—Ä—Å–µ—Ä–∞).\n",
    "–Ø–¥–µ—Ä–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è - –¥—ñ–π—Å–Ω–æ–∑–Ω–∞—á–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤—ñ–¥ –¥–≤–æ—Ö –∑–º—ñ–Ω–Ω–∏—Ö. –ó–∞–∑–≤–∏—á–∞–π —Ñ—É–Ω–∫—Ü—ñ—è —î —Å–∏–º–µ—Ç—Ä–∏—á–Ω–æ—é —Ç–∞ –Ω–µ–≤—ñ–¥—î–º–Ω–æ—é, –æ—Ç–∂–µ –º–æ–∂–µ –±—É—Ç–∏ —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω–æ—é —è–∫ –º—ñ—Ä–∞ —Å—Ö–æ–∂–æ—Å—Ç—ñ, –∞–ª–µ –Ω–µ –∑–∞–≤–∂–¥–∏.\n",
    "–¢–µ–æ—Ä–µ–º–∞ –ú–µ—Ä—Å–µ—Ä–∞: —è–∫—â–æ –º–∞—Ç—Ä–∏—Ü—è –ì—Ä–∞–º–∞ —î –¥–æ–¥–∞—Ç–Ω—å–æ –≤–∏–∑–Ω–∞—á–µ–Ω—é, –º–∏ –º–æ–∂–µ–º–æ –ø–æ—Ä–∞—Ö—É–≤–∞—Ç–∏ —Ä–æ–∑–∫–ª–∞–¥ –≤–ª–∞—Å–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ —è–∫ $K = U^{T} * \\lambda * U $ –¥–µ $\\lambda$ –¥—ñ–∞–≥–æ–Ω–∞–ª—å–Ω–∞ –º–∞—Ç—Ä–∏—Ü—è –≤–ª–∞—Å–Ω–∏—Ö –Ω–µ–≤—ñ–¥—î–º–Ω–∏—Ö —á–∏—Å–µ–ª. –†–æ–∑–≥–ª—è–¥–∞—é—á–∏ –µ–ª–µ–º–µ–Ω—Ç–∏ –º–∞—Ç—Ä–∏—Ü—ñ K:\n",
    "     $k_{i,j} = (\\lambda^{1/2} * U[:, i]) ^{T} * (\\lambda^{1/2} * U[:, j])$ –ú–æ–∂–µ–º–æ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç–∏ $k_{i,j} = \\phi(x_i)^{T} \\phi(x_j)$. –Ø–∫—â–æ —è–¥–µ—Ä–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –Ω–∞–ª–µ–∂–∏—Ç—å –¥–æ –∫–ª–∞—Å—Å—É –ú–µ—Ä—Å–µ—Ä–∞,—Ç–æ–¥—ñ —ñ—Å–Ω—É—î —Ñ—É–Ω–∫—Ü—ñ—è $\\phi$ —Ç–∞–∫–∞, —â–æ: $k(x, x') = \\phi(x)^{T}\\phi(x')$\n",
    "\n",
    "### 9. –í—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ç–∞ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –∑ —Ç–æ—á–∫–∏ –∑–æ—Ä—É –≤–∏—Ä—ñ—à–µ–Ω—è –∑–∞–¥–∞—á—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó.\n",
    "1. –í—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ç–∞ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –∑ —Ç–æ—á–∫–∏ –∑–æ—Ä—É –≤–∏—Ä—ñ—à–µ–Ω—è –∑–∞–¥–∞—á—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó.\n",
    "* –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è –¥–∞—î –Ω–∞ –≤–∏–≤—ñ–¥ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ (–≤—ñ–¥ 0 –¥–æ 1), –ª—ñ–Ω—ñ–π–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è - –¥—ñ–π—Å–Ω—ñ —á–∏—Å–ª–∞. \n",
    "* –£ –≤–∏–ø–∞–¥–∫—É –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –º–∞—î–º–æ –≤—ñ–¥–Ω–æ—Å–∏—Ç–∏ –Ω–æ–≤–∏–π –æ–±'—î–∫—Ç –¥–æ –∫–ª–∞—Å—É 0, —è–∫—â–æ –≤–∏–≤—ñ–¥ –º–æ–¥–µ–ª—ñ <0.5, —ñ–Ω–∞–∫—à–µ –≤—ñ–¥–Ω–æ—Å–∏–º–æ –æ–±'—î–∫—Ç –¥–æ –∫–ª–∞—Å—É 1.\n",
    "* –î–ª—è –ª—ñ–Ω—ñ–π–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó –º–∞—î–º–æ —Å–ø–µ—Ä—à—É –≤—ñ–¥–Ω–∞–π—Ç–∏ –∑–Ω–∞—á–µ–Ω–Ω—è (max-min)/2 (–∞–±–æ –º–æ–∂–ª–∏–≤–æ —ñ–Ω—à–∏–π decision boundary), —Ç–∞ –ø–æ—Ç—ñ–º –≤—ñ–¥–Ω–µ—Å—Ç–∏ –æ–±'—î–∫—Ç –¥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—É.\n",
    "* –ó–∞–≥–∞–ª–æ–º –æ–±–∏–¥–≤–∞ –º–µ—Ç–æ–¥–∏ –≤—ñ–¥–Ω–æ—Å—è—Ç—å—Å—è –¥–æ –ª—ñ–Ω—ñ–π–Ω–∏—Ö –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤ —Ç–∞ —î –¥–æ—Å–∏—Ç—å —Å—Ö–æ–∂–∏–º–∏.\n",
    "* –î–µ—è–∫—ñ –ø–µ—Ä–µ–≤–∞–≥–∏ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó:\n",
    "    *\tLR models are easy to extend to multi-class classification;\n",
    "    *\tLR model can be easily be extended to handle non-linear decision boundaries by using kernels or by learning features from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. –ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ (Support Vector Machine, SVM). –í—ñ–¥–º—ñ–Ω–Ω–æ—Å—Ç—ñ –≤—ñ–¥ —ñ–Ω—à–∏—Ö –º–µ—Ç–æ–¥—ñ–≤ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö.\n",
    "\n",
    "–ú–µ—Ç–æ–¥ –æ–ø–æ—Ä–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ (–∞–Ω–≥–ª. SVM, support vector machine) ‚Äî –Ω–∞–±—ñ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –∑ —É—á–∏—Ç–µ–ª–µ–º,\n",
    "—â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ —Ä–µ–≥—Ä–µ—Å—ñ–π–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É. \n",
    "–ö–ª—é—á–æ–≤—ñ –≤–ª–∞—Å—Ç–∏–≤–æ—Å—Ç—ñ: 1) —è–¥–µ—Ä–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –Ω–µ–¥–æ–Ω–∞–≤—á–∞–Ω–Ω—è (underfitting); 2) –ø—Ä–∏–Ω—Ü–∏–ø —Ä–æ–∑—Ä—ñ–¥–∂–µ–Ω–æ—Å—Ç—ñ —Ç–∞ 3) –ø—Ä–∏–Ω—Ü–∏–ø –≤–µ–ª–∏–∫–æ—ó –≥—Ä–∞–Ω—ñ (large margin) –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è.\n",
    "\n",
    "### 11. –î–µ—Ä–µ–≤–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó —Ç–∞ —Ä–µ–≥—Ä–µ—Å—ñ—ó. –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ, –æ–±–º–µ–∂–µ–Ω–Ω—è —Ç–∞ –ø–µ—Ä–µ–≤–∞–≥–∏.\n",
    "\n",
    "$ùëì(ùê±)=ùîº[ùë¶|ùê±]=‚àë_{ùëö=1}^{ùëÄ}ùë§_ùëö ùïÄ(ùê±‚àà‚Ñõ_ùëö ) =‚àë_{ùëö=1}^{ùëÄ}(w_ùëö ùúô(ùê±, ùêØ_ùëö ))$  –¥–µ $R_m$ - m-–π —Ä–µ–≥—ñ–æ–Ω\n",
    "\n",
    "–ü–µ—Ä–µ–≤–∞–≥–∏: \n",
    "- —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–æ–≤–∞–Ω—ñ\n",
    "- –º–æ–∂—É—Ç—å –ø–æ—î–¥–Ω—É–≤–∞—Ç–∏ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ñ —Ç–∞ –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è\n",
    "- –Ω–µ—á—É—Ç–ª–∏–≤—ñ –¥–ª—è –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—ó —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—ó –≤—Ö–æ–¥—É\n",
    "- –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø—Ä–æ–≤–æ–¥—è—Ç—å –≤—ñ–¥–±—ñ—Ä –∑–º—ñ–Ω–Ω–∏—Ö\n",
    "- –≤—ñ–¥–Ω–æ—Å–Ω–æ –Ω–µ—á—É—Ç–ª–∏–≤—ñ –¥–æ –≤–∏–∫–∏–¥—ñ–≤\n",
    "- –º–æ–∂—É—Ç—å —Å–ø—Ä–∏–π–º–∞—Ç–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –¥–∞–Ω–Ω—ñ\n",
    "\n",
    "–ù–µ–¥–æ–ª—ñ–∫–∏:\n",
    "- –Ω–µ –¥—É–∂–µ —Ç–æ—á–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á—É—é—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "- –Ω–µ—Å—Ç–∞–±—ñ–ª—å–Ω—ñ (–º–∞–ª–µ–Ω—å–∫–∞ –∑–º—ñ–Ω–∞ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –º–æ–∂–µ—Ç –≤–ø–ª–∏–Ω—É—Ç–∏ –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–µ—Ä–µ–≤–∞)\n",
    "\n",
    "### 12. –ü–æ–Ω—è—Ç—Ç—è –ø–æ–¥—ñ–ª—å–Ω–∏—Ö —è–¥–µ—Ä–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π. –í–∏–º–æ–≥–∏ –¥–æ —Ñ—É–Ω–∫—Ü—ñ–π.\n",
    "  $\\phi(x1, ..., xn) = \\phi(x1) * ... * \\phi(xn)\\$\n",
    "  \n",
    "### 13. –ê–Ω—Å–∞–º–±–ª–µ–≤—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏. –û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ —Ç–∞ –ø—Ä–∏–∫–ª–∞–¥–∏.\n",
    "\n",
    "–ê–Ω—Å–∞–º–±–ª–µ–≤—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏\n",
    "–ú–æ–¥–µ–ª—ñ —â–æ –∞–≥—Ä—É–≥—É—é—Ç—å –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó –≤–∞–≥ –±—ñ–ª—å—à –ø—Ä–æ—Å—Ç–∏—Ö –º–æ–¥–µ–ª–µ–π f(y|x, $\\theta$) = $\\sum$ $weights_i * f_m(y|x)$, –¥–µ –≤–∞–≥–∏ - —Ç—Ä–µ–Ω–æ–≤–∞–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–∏. –ü—Ä–∏–∫–ª–∞–¥–æ–º –∞–Ω—Å–∞–º–±–ª–µ–≤–∏—Ö –º–µ—Ç–æ–¥—ñ–≤ —î\n",
    "Random Forest\n",
    "–ë—É—Å—Ç–∏–Ω–≥–æ–≤—ñ –¥–µ—Ä–µ–≤–∞\n",
    "–¢–∞–∫–æ–∂ –ø—ñ–¥–≤–∏–¥–æ–º –∞–Ω—Å–∞–º–±–ª–µ–≤–∏—Ö –º–æ–¥–µ–ª–µ–π –º–æ–∂–Ω–∞ –≤–∏–¥—ñ–ª–∏—Ç–∏ Stacking, –¥–µ –º–∏ –ø–æ—î–¥–Ω—É—î–º–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –±—ñ–ª—å—à –ø—Ä–æ—Å—Ç–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –±—ñ–ª—å—à —Å–∫–ª–∞–¥–Ω–∏—Ö.\n",
    "\n",
    "### 14. –ú–µ—Ç–æ–¥–∏ –∞–≥—Ä–µ–≥–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö (bagging) –ø—Ä–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤.\n",
    "* bootstrap aggregating (bagging) is a technique to reduce the variance of an estimate to average together many estimates. For example, we can train ùëÄ different trees on different subsets of the data, chosen randomly with replacement, and then compute the ensemble f(x) = sum(f_m(x))/M\n",
    "\n",
    "### 15. –ê–Ω—Å–∞–º–ª–µ–≤—ñ –º–µ—Ç–æ–¥–∏ –ø—ñ–¥—Å–∏–ª–µ–Ω–Ω—è (boosting) –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤.\n",
    "\n",
    "–ë—É—Å—Ç–∏–Ω–≥–æ–≤—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∏ - –∂–∞–¥—ñ–±–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏, —è–∫—ñ –ø–æ—î–¥–Ω—É—é—Ç—å –≤ —Å–æ–±—ñ –±—ñ–ª—å—à –ø—Ä–æ—Å—Ç—ñ –º–æ–¥–µ–ª–∏ –∑–∞ $f(x) = w_0 + sum(w_m * \\phi_m(x)) $ –¥–µ –∫–æ–∂–Ω–∏–π $\\phi_m$ –±–∞–∑–æ–≤–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–∞–≤—á–∞–Ω–Ω—è. –í –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≤—ñ–¥ —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç–∏ —ñ—Å–Ω—É—é —Ä—ñ–∑–Ω—ñ —Ç–∏–ø–∏ –±—É—Å—Ç–∏–Ω–≥–æ–≤–∏—Ö –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä—ñ–≤ (L2Boosting, Gradient Boosting, AdaBosting, LogitBoosting)\n",
    "![image.png](attachment:image.png)![image.png](attachment:image.png)![image.png](attachment:image.png)![image.png](attachment:image.png)![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 1. –ó–∞–¥–∞–Ω–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å –≤–∏—Ö—ñ–¥–Ω–∏—Ö —Å—Ç–∞–Ω—ñ–≤ –º–∞—Ä–∫—ñ–≤—Å—å–∫–æ—ó –º–æ–¥–µ–ª—ñ:\n",
    "  X = {1, 3, 2, 6, 10, 1, 4, 3, 7, 9, 9}\n",
    "  –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–∞–Ω—ñ–≤ –º–æ–¥–µ–ª—ñ —Ä—ñ–≤–Ω–∞ 10. –†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –ø–µ—Ä–µ—Ö–æ–¥—ñ–≤ (transition matrix) –Ω–∞ 4 —ñ—Ç–µ—Ä–∞—Ü—ñ—ó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  2,  6, 10,  1,  4,  3,  7,  9,  9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 3, 2, 6, 10, 1, 4, 3, 7, 9, 9])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_filled(x):\n",
    "    matrix = np.zeros((10, 10))\n",
    "    for i in range(x.shape[0] - 1):\n",
    "        val_1 = x[i]\n",
    "        val_2 = x[i+1]\n",
    "        matrix[val_2 - 1][val_1 - 1] += 1\n",
    "        #print(val_1, val_2)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(matrix, epsilon=1e-10):\n",
    "    row_sums = (matrix + epsilon).sum(axis = 1)\n",
    "    res = matrix / row_sums[:, np.newaxis]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized matrix\n",
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.5 0.  0.  0.5 0.  0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.5 0.  0.5 0. ]\n",
      " [0.  0.  0.  0.  0.  1.  0.  0.  0.  0. ]]\n",
      "Matrix in power of 4\n",
      "[[0.     0.     1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.5    0.     0.     0.     0.5   ]\n",
      " [0.     0.5    0.     0.     0.     0.5    0.     0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.5    0.     0.     0.     0.     0.     0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.     0.5    0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.375  0.     0.125  0.125  0.     0.     0.0625 0.     0.0625 0.25  ]\n",
      " [0.5    0.     0.     0.5    0.     0.     0.     0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "matrix = matrix_filled(x)\n",
    "matrix_norm = normalize_matrix(matrix)\n",
    "print('Normalized matrix')\n",
    "print(matrix_norm)\n",
    "print('Matrix in power of 4')\n",
    "print(np.linalg.matrix_power(matrix_norm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. –ó–∞–¥–∞–Ω–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å —Å—Ç–∞–Ω—ñ–≤ –º–∞—Ä–∫—ñ–≤—Å—å–∫–æ—ó –º–æ–¥–µ–ª—ñ:\n",
    "  X = {2,5,4,7,3,4,2,3,5,4,6,7,7,6,1}\n",
    "  pi = {0.3; 0.1; 0.1; 0.2; 0.1; 0.1; 0.1}\n",
    "  –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–∞–Ω—ñ–≤ —Ä—ñ–≤–Ω–∞ 7. –†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –∑–Ω–∞—á–µ–Ω–Ω—è –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –≤–µ–∫—Ç–æ—Ä–∞ —Å—Ç–∞–Ω—É pi –Ω–∞ 3 —ñ—Ç–µ—Ä–∞—Ü—ñ—ó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,pi,n = np.array([2,5,4,7,3,4,2,3,5,4,6,7,7,6,1]),np.array([0.3, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1]),7\n",
    "\n",
    "n_states = 7\n",
    "n_iterations = 3\n",
    "\n",
    "matrix = matrix_filled(x, n_states)\n",
    "matrix_norm = normalize_matrix(matrix)\n",
    "matrix_norm2 = np.linalg.matrix_power(matrix_norm, n_iterations)\n",
    "pi2 = np.dot(pi,matrix_norm)\n",
    "pi3 = np.dot(pi2,matrix_norm2)\n",
    "print(pi3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. –ó–∞–¥–∞–Ω–æ –µ–º–ø—ñ—Ä–∏—á–Ω—ñ —Ä–æ–∑–ø–æ–¥—ñ–ª–∏ —Ç—Ä—å–æ—Ö –∫–ª–∞—Å—ñ–≤:\n",
    "  X1 = {(1, 3); (2, 4); (3, 5)}\n",
    "  X2 = {(2, 5); (0, 8); (4, 1); (1, 1)}\n",
    "  X3 = {(1, 1); (-5 , 4); (0, 8)}\n",
    "\n",
    "–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ GMM –≤–∏—Ä—ñ—à–∏—Ç–∏ –∑–∞–¥–∞—á—É –±–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –Ω–æ–≤–æ–≥–æ –µ–ª–µ–º–µ–Ω—Ç–∞ x = (2, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1, 3], [2, 4], [3, 5]])\n",
    "x2 = np.array([[2, 5], [0, 8], [4, 1],[1, 1]])\n",
    "x3 = np.array([[1, 1], [-5 , 4], [0, 8]])\n",
    "\n",
    "x_new = np.array([2, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(x1, axis=0, keepdims=True)\n",
    "mean_2 = np.mean(x2, axis=0, keepdims=True)\n",
    "mean_3 = np.mean(x3, axis=0, keepdims=True)\n",
    "\n",
    "cov_1 = np.cov(x1)\n",
    "cov_2 = np.cov(x2)\n",
    "cov_3 = np.cov(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== model1 ==\n",
      "Mean:  [[2. 4.]] \n",
      "Cov:  [[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "== model2 ==\n",
      "Mean:  [[1.75 3.75]] \n",
      "Cov:  [[  4.5  12.   -4.5   0. ]\n",
      " [ 12.   32.  -12.    0. ]\n",
      " [ -4.5 -12.    4.5   0. ]\n",
      " [  0.    0.    0.    0. ]]\n",
      "== model3 ==\n",
      "Mean:  [[-1.33333333  4.33333333]] \n",
      "Cov:  [[ 0.   0.   0. ]\n",
      " [ 0.  40.5 36. ]\n",
      " [ 0.  36.  32. ]]\n"
     ]
    }
   ],
   "source": [
    "print('== model1 ==')\n",
    "print('Mean: ', mean_1,'\\nCov: ', cov_1)\n",
    "print('== model2 ==')\n",
    "print('Mean: ', mean_2,'\\nCov: ', cov_2)\n",
    "print('== model3 ==')\n",
    "print('Mean: ', mean_3,'\\nCov: ', cov_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 4. –û–±—á–∏—Å–ª–∏—Ç–∏ –ø–µ—Ä—à—ñ 2 –≥–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –¥–ª—è –∑–∞–¥–∞–Ω–æ—ó –≤–∏–±—ñ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω—å: [–ó–∞–ª–∏—à–∏—Ç–∏ 2 –≥–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ (–ø–µ—Ä—à—ñ 2 —Ä—è–¥–∫–∏) –≤ s, –ø–µ—Ä–µ–º–Ω–æ–∂–∏—Ç–∏ –Ω–∞ —ñ–Ω—à—ñ]\n",
    "  X = {(1,2,3);\n",
    "     (2,3,4);\n",
    "     (7,7,9);\n",
    "     (0, 11, 0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.21299335,  0.11166707,  0.7341609 ,  0.63495832],\n",
       "        [-0.31466555,  0.15717558,  0.5437956 , -0.76194998],\n",
       "        [-0.7774661 ,  0.46334971, -0.40586529,  0.12699166],\n",
       "        [-0.50116454, -0.86494702, -0.02382178,  0.0115447 ]]),\n",
       " array([16.44752767,  8.42106835,  1.25077632]),\n",
       " array([[-0.3820992 , -0.74935615, -0.54080086],\n",
       "        [ 0.4357483 , -0.66216163,  0.60964366],\n",
       "        [-0.8149378 , -0.0027087 ,  0.57954209]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "X = np.array([[1,2,3],\n",
    "              [2,3,4],\n",
    "              [7,7,9],\n",
    "              [0,11,0]])\n",
    "U,s,V=np.linalg.svd(X)\n",
    "\n",
    "U,s,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(U,s,V,n=2):\n",
    "    s[n:]=0\n",
    "    S = np.zeros((U.shape[0],V.shape[0]))\n",
    "    S[:s.shape[0],:s.shape[0]]=np.diag(s)\n",
    "    return U@S@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.74833381,  2.00248732,  2.46782326],\n",
       "       [ 2.55429353,  3.00184237,  3.60581479],\n",
       "       [ 6.58629952,  6.99862494,  9.29420263],\n",
       "       [-0.02428166, 10.99991929,  0.01726787]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct(U,s,V,n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 5. –í–∏–∑–Ω–∞—á–∏—Ç–∏ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ (latent variables) \n",
    "–∑–∞ –≤—ñ–¥–æ–º–æ—é –º–∞—Ç—Ä–∏—Ü–µ—é –∑–º—ñ—à—É–≤–∞–Ω–Ω—è W —Ç–∞ –≤–µ–∫—Ç–æ—Ä–æ–º –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ–≥–æ –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è mu. –†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –≤–∏–ø–∞–¥–æ–∫, –∫–æ–ª–∏ –≤–ø–ª–∏–≤ –ø–æ–º–∏–ª–æ–∫ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π (eps -> 0)\n",
    "  mu = (1, 3, 5, 7)\n",
    "  W = (1, 2, 3, 7, 11)\n",
    "    (3,7,2,3,4)\n",
    "    (9,4,0,0,1)\n",
    "    (1,1,1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.67  1.62 -7.95 -2.56  3.57]\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([1, 3, 5, 7])\n",
    "W = np.array([[1, 2, 3, 7, 11],\n",
    "              [3, 7, 2, 3, 4],\n",
    "              [9, 4, 0, 0, 1],\n",
    "              [1, 1, 1, 1, 1]])\n",
    "# W*z + mu = epsilon -> 0\n",
    "# WZ = -mu\n",
    "# z = W^(-1) * (-mu)\n",
    "np.set_printoptions(suppress=True)\n",
    "z = np.dot(np.linalg.pinv(W),(-mu))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 6. –í–∏—Ä—ñ—à–∏—Ç–∏ —Å–∏—Å—Ç–µ–º—É –ª—ñ–Ω—ñ–π–Ω–∏—Ö –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–Ω–∏—Ö —Ä—ñ–≤–Ω—è–Ω—å:\n",
    "  (1) x1 + 4x2 + x3 = 0\n",
    "  (2) 8x2 - 3x3 = 5\n",
    "  (3) x1 + 78x3 = 21\n",
    "  (4) 3x1 + 2x2 = 4\n",
    "  (5) 6x1+x2+x3 = 77\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.2248782 , 11.04936545,  0.97260676])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1,4,1],\n",
    "              [0,8,-3],\n",
    "              [1,0,78],\n",
    "              [3,2,0],\n",
    "              [6,1,1]\n",
    "             ])\n",
    "y = np.array([0,5,21,4,77])\n",
    "\n",
    "\n",
    "lr = LinearRegression().fit(X,y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. –í–∏—Ä—ñ—à–∏—Ç–∏ –∑–∞–¥–∞—á—É –±–∞–≥–∞—Ç–æ–∫–ª–∞—Å–æ–≤–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –≤–∏–º—ñ—Ä—É x={1, 2.5, 7} –ø—Ä–∏ –≤—ñ–¥–æ–º–∏—Ö –≥—É—Å—Ç–∏–Ω–∞—Ö —Ä–æ–∑–ø–æ–¥—ñ–ª—É –∫–ª–∞—Å—ñ–≤ (–º–æ–¥–µ–ª—å GMM):\n",
    "  C1 = {(1, 4, 7), (2, 8, 9)}\n",
    "  C2 = {(1, 1, 0), (8, 10, 28)}\n",
    "  C3 = {(0, 7, 11), (7, 5, 15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov_vect(X):\n",
    "    Y = X-X.mean(axis=1,keepdims=True)\n",
    "    matr = np.zeros(X.shape)\n",
    "    for i in range(Y.shape[0]):\n",
    "        col = np.array(Y[:,i],ndmin=2)\n",
    "        rm = np.dot(col.T,col)\n",
    "        matr+=rm   \n",
    "    return matr/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1, 4, 7], [2, 8, 9]])\n",
    "x2 = np.array([[1, 1, 0], [8, 10, 28]])\n",
    "x3 = np.array([[0, 7, 11], [7, 5, 15]])\n",
    "\n",
    "x_new = np.array([1, 2.5, 7])\n",
    "\n",
    "mean_1 = np.mean(x1, axis=0, keepdims=True)\n",
    "mean_2 = np.mean(x2, axis=0, keepdims=True)\n",
    "mean_3 = np.mean(x3, axis=0, keepdims=True)\n",
    "\n",
    "cov_1 = np.cov(x1)\n",
    "cov_2 = np.cov(x2)\n",
    "cov_3 = np.cov(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 8, 9]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,2) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-d89246eef87f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc_cov_vect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-1d3eaa382ade>\u001b[0m in \u001b[0;36mcalc_cov_vect\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mrm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmatr\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mrm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,2) (2,3) "
     ]
    }
   ],
   "source": [
    "calc_cov_vect(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== model1 ==\n",
      "Mean:  [[1.5 6.  8. ]] \n",
      "Cov:  [[ 9.         10.5       ]\n",
      " [10.5        14.33333333]]\n",
      "== model2 ==\n",
      "Mean:  [[ 4.5  5.5 14. ]] \n",
      "Cov:  [[  0.33333333  -6.33333333]\n",
      " [ -6.33333333 121.33333333]]\n",
      "== model3 ==\n",
      "Mean:  [[ 3.5  6.  13. ]] \n",
      "Cov:  [[31. 19.]\n",
      " [19. 28.]]\n"
     ]
    }
   ],
   "source": [
    "print('== model1 ==')\n",
    "print('Mean: ', mean_1,'\\nCov: ', cov_1)\n",
    "print('== model2 ==')\n",
    "print('Mean: ', mean_2,'\\nCov: ', cov_2)\n",
    "print('== model3 ==')\n",
    "print('Mean: ', mean_3,'\\nCov: ', cov_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 6. , 8. ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.        , 10.5       ],\n",
       "       [10.5       , 14.33333333]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension mismatch: array 'cov' is of shape (2, 2), but 'mean' is a vector of length 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b110c99926fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    361\u001b[0m         return multivariate_normal_frozen(mean, cov,\n\u001b[0;32m    362\u001b[0m                                           \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                                           seed=seed)\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         self.dim, self.mean, self.cov = self._dist._process_parameters(\n\u001b[1;32m--> 735\u001b[1;33m                                                             None, mean, cov)\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmaxpts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m_process_parameters\u001b[1;34m(self, dim, mean, cov)\u001b[0m\n\u001b[0;32m    419\u001b[0m                        \" but 'mean' is a vector of length %d.\")\n\u001b[0;32m    420\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             raise ValueError(\"Array 'cov' must be at most two-dimensional,\"\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension mismatch: array 'cov' is of shape (2, 2), but 'mean' is a vector of length 3."
     ]
    }
   ],
   "source": [
    "stats.multivariate_normal(mean_1[0], cov_1).pdf(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 8. –ó–∞–¥–∞–Ω–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å —Å—Ç–∞–Ω—ñ–≤ –º–∞—Ä–∫—ñ–≤—Å—å–∫–æ—ó –º–æ–¥–µ–ª—ñ –ø–µ—Ä—à–æ–≥–æ –ø–æ—Ä—è–¥–∫—É:\n",
    "  X = {1, 7, 5, 4, 3, 10, 1, 1, 5, 7, 5, 6, 1}\n",
    "  –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å—Ç–∞–Ω—ñ–≤ –º–æ–¥–µ–ª—ñ —Ä—ñ–≤–Ω–∞ 10. –†–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –ø–µ—Ä–µ—Ö–æ–¥—ñ–≤ (transition matrix) –Ω–∞ 3 —ñ—Ç–µ—Ä–∞—Ü—ñ—ó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,n = np.array([1, 7, 5, 4, 3, 10, 1, 1, 5, 7, 5, 6, 1]),10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = matrix_filled(X)\n",
    "normalized_x = normalize_matrix(x)\n",
    "np.linalg.matrix_power(normalized_x,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 9. –û–±—á–∏—Å–ª–∏—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –ì—Ä–∞–º–∞ –¥–ª—è —è–¥–µ—Ä–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó k(x) = xsin(x) + x^2 / 5 \n",
    "–Ω–∞ –º–Ω–æ–∂–∏–Ω—ñ X = {1, 0, 7, 6, 4, 10}. –ê—Ä–≥—É–º–µ–Ω—Ç —Ñ—É–Ω–∫—Ü—ñ—ó sin(x) –∑–∞–¥–∞–Ω–æ –≤ —Ä–∞–¥—ñ–∞–Ω–∞—Ö.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x):\n",
    "    return x * np.sin(x) + (x ** 2) / 5\n",
    "\n",
    "X = np.array([1,0,7,6,4,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.08,   0.  ,  15.  ,   5.75,   0.18,  15.16],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [ 15.  ,   0.  , 207.33,  79.53,   2.49, 209.65],\n",
       "       [  5.75,   0.  ,  79.53,  30.51,   0.95,  80.42],\n",
       "       [  0.18,   0.  ,   2.49,   0.95,   0.03,   2.52],\n",
       "       [ 15.16,   0.  , 209.65,  80.42,   2.52, 211.99]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def form_gram_matrix(X,kernel):\n",
    "    n = X.shape[0]\n",
    "    K = np.array([[kernel(X[i])*kernel(X[j]) for i in range(n)] for j in range(n)])\n",
    "    return K\n",
    "form_gram_matrix(X,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 10. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —á–∏ —î –≤—ñ–¥–Ω–æ—Å–∏—Ç—å –∑–∞–¥–∞–Ω–∞ —è–¥–µ—Ä–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è k(x) = exp{sin(x) + 1} + xtan(x) –¥–æ –∫–ª–∞—Å—É —è–¥–µ—Ä–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π –ú–µ—Ä—Å–µ–Ω–∞. \n",
    "–ü–µ—Ä–µ–≤—ñ—Ä–∫—É –≤–∏–∫–æ–Ω–∞—Ç–∏ –Ω–∞ –º–Ω–æ–∂–∏–Ω—ñ X={7, 6, 2, 1, 0, 4, 6, 9}. –ê—Ä–≥—É–º–µ–Ω—Ç–∏ —Ç—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π –∑–∞–¥–∞–Ω–æ –≤ —Ä–∞–¥—ñ–∞–Ω–∞—Ö.\n",
    "\n",
    "–ú–∞—î–º–æ —Å—Ñ–æ—Ä–º—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –≥—Ä–∞–º–∞ —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —â–æ –≤–æ–Ω–∞ positive definite. –Ø–∫—â–æ –≤–æ–Ω–∞ –±—É–¥–µ –≤–æ–Ω–∞ positive definite, —è–¥–µ—Ä–Ω–∞ —Ñ-—Ü—ñ—è –≤—ñ–¥–Ω–æ—Å–∏—Ç—å—Å—è –¥–æ –∫–ª–∞—Å—É —è–¥–µ—Ä–Ω–∏—Ö —Ñ-–π –ú–µ—Ä—Å–µ–Ω–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([7,6,2,1,0,4,6,9])\n",
    "def k(x):\n",
    "    return np.exp(np.sin(x)+1) + x*np.tan(x)\n",
    "\n",
    "def form_gram_matrix(X,kernel):\n",
    "    n = X.shape[0]\n",
    "    K = np.array([[kernel(X[i])*kernel(X[j]) for i in range(n)] for j in range(n)])\n",
    "    return K\n",
    "\n",
    "def check_positive_definite(K,X):\n",
    "    return X.T@K@X \n",
    "\n",
    "def check_kernel_function(X,kernel,print_gram=False):\n",
    "    K = form_gram_matrix(X,kernel)\n",
    "    \n",
    "    if print_gram:\n",
    "        print(f'Gram matrix:\\n{K}')\n",
    "    \n",
    "    prod = check_positive_definite(K,X)\n",
    "    print(f'X.T@K@X={prod}')\n",
    "    if prod>0:\n",
    "        return \"kernel function is positive-definite\"\n",
    "    return \"kernel function isn't positive-definite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram matrix:\n",
      "[[128.68   3.51  26.98  89.2   30.84  67.     3.51   0.38]\n",
      " [  3.51   0.1    0.74   2.43   0.84   1.83   0.1    0.01]\n",
      " [ 26.98   0.74   5.66  18.7    6.46  14.05   0.74   0.08]\n",
      " [ 89.2    2.43  18.7   61.83  21.37  46.44   2.43   0.27]\n",
      " [ 30.84   0.84   6.46  21.37   7.39  16.06   0.84   0.09]\n",
      " [ 67.     1.83  14.05  46.44  16.06  34.89   1.83   0.2 ]\n",
      " [  3.51   0.1    0.74   2.43   0.84   1.83   0.1    0.01]\n",
      " [  0.38   0.01   0.08   0.27   0.09   0.2    0.01   0.  ]]\n",
      "X.T@K@X=14321.124233689508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kernel function is positive-definite'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_kernel_function(X,k,print_gram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 11. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏, —á–∏ –Ω–∞–ª–µ–∂–∏—Ç—å –∑–∞–¥–∞–Ω–∞ —è–¥–µ—Ä–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è k(x) = ln(1 + exp(-x) + tg(x)^2) –¥–æ –∫–ª–∞—Å—É —è–¥–µ—Ä–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π –ú–µ—Ä—Å–µ–Ω–∞. \n",
    "  –ü–µ—Ä–µ–≤—ñ—Ä–∫—É –≤–∏–∫–æ–Ω–∞—Ç–∏ –Ω–∞ –º–Ω–æ–∂–∏–Ω—ñ X={1,9,7,5,3,2}. –ê—Ä–≥—É–º–µ–Ω—Ç–∏ —Ç—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–Ω–∏—Ö —Ñ—É–Ω–∫—Ü—ñ–π –∑–∞–¥–∞–Ω–æ –≤ —Ä–∞–¥—ñ–∞–Ω–∞—Ö.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,9,7,5,3,2])\n",
    "def k(x):\n",
    "    return np.log(1+np.exp(-x)+np.tan(x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram matrix:\n",
      "[[1.78 0.25 0.75 3.36 0.09 2.37]\n",
      " [0.25 0.03 0.11 0.47 0.01 0.33]\n",
      " [0.75 0.11 0.32 1.43 0.04 1.  ]\n",
      " [3.36 0.47 1.43 6.35 0.17 4.48]\n",
      " [0.09 0.01 0.04 0.17 0.   0.12]\n",
      " [2.37 0.33 1.   4.48 0.12 3.16]]\n",
      "X.T@K@X=544.14218243972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kernel function is positive-definite'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_kernel_function(X,k,print_gram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 12. –í–∏–∑–Ω–∞—á–∏—Ç–∏ –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏—Ö–æ–≤–∞–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ (latent variables) –∑–∞ –≤—ñ–¥–æ–º–æ—é –º–∞—Ç—Ä–∏—Ü–µ—é –∑–º—ñ—à—É–≤–∞–Ω–Ω—è W —Ç–∞ –≤–µ–∫—Ç–æ—Ä–æ–º –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ–≥–æ –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è mu. \n",
    "  –†–æ–∑–≥–ª—è–Ω—É—Ç–∏ –≤–∏–ø–∞–¥–æ–∫, –∫–æ–ª–∏ –≤–ø–ª–∏–≤ –ø–æ–º–∏–ª–æ–∫ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π (eps -> 0)\n",
    "  mu = (4,5,3,6)\n",
    "  W = (1,2,3)\n",
    "    (95,7,0)\n",
    "    (1,2,5)\n",
    "    (0,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18  1.67 -1.67]\n"
     ]
    }
   ],
   "source": [
    "W =np.array([[1,2,3],\n",
    "    [95,7,0],\n",
    "    [1,2,5],\n",
    "    [0,0,1]])\n",
    "mu = np.array([4,5,3,6])\n",
    "z = np.dot(np.linalg.pinv(W),(-mu))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 13. –û–±—á–∏—Å–ª–∏—Ç–∏ –ø–µ—Ä—à—ñ 3 –≥–æ–ª–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –¥–ª—è –∑–∞–¥–∞–Ω–æ—ó –≤–∏–±—ñ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω—å:\n",
    "  X = {(1,2,3,8);\n",
    "     (5,3,6,2);\n",
    "     (7,5,6,8);\n",
    "     (0,0,0,1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,8],\n",
    "     [5,3,6,2],\n",
    "     [7,5,6,8],\n",
    "     [0,0,0,1]])\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "u, s, vh = np.linalg.svd(X, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45103945,  0.74955999,  0.47409566, -0.09978246],\n",
       "       [-0.45211097, -0.64452157,  0.60908097,  0.09595827],\n",
       "       [-0.76864884, -0.06716484, -0.63454343, -0.04497204],\n",
       "       [-0.03657932,  0.13505797, -0.04010375,  0.98934978]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.10171748,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  5.64592816,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.62212023,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[n_components:] = 0\n",
    "np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47317681, -0.35678615, -0.50741554, -0.62556919],\n",
       "       [-0.52129636, -0.13642911, -0.35803476,  0.76252759],\n",
       "       [-0.56857901, -0.24491583,  0.78262522, -0.0650531 ],\n",
       "       [ 0.42552523, -0.8911268 ,  0.04287594,  0.15160132]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.00650628,  1.98637468,  3.00065557,  8.00231798],\n",
       "        [ 4.99374308,  3.01310313,  5.99936955,  1.99777085],\n",
       "        [ 7.00293239,  4.99385906,  6.00029547,  8.00104472],\n",
       "        [-0.06451019,  0.135096  , -0.00650005,  0.97701704]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconst = np.matrix(u) * np.diag(s) * np.matrix(vh)\n",
    "reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. –û–±—á–∏—Å–ª–∏—Ç–∏ –∞–Ω—Ç–∏–≥—Ä–∞–¥—ñ–µ–Ω—Ç –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç –≤ —Ç–æ—á—Ü—ñ x = 0, y = 1:\n",
    "  loss = 1/2 * (y - f(x)) ^2\n",
    "  f(x) = tg(x^2 - 2) + exp(sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tan(x**2-2)+np.exp(np.sin(x))\n",
    "\n",
    "def loss(x,y):\n",
    "    return 0.5*(y-f(x)) **2\n",
    "\n",
    "x,y=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 15. –í–∏—Ä—ñ—à–∏—Ç–∏ —Å–∏—Å—Ç–µ–º—É –ª—ñ–Ω—ñ–π–Ω–∏—Ö –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–Ω–∏—Ö —Ä—ñ–≤–Ω—è–Ω—å:\n",
    "    *  2x1 - 2x2 + 8x3 + 12x4 = 0\n",
    "    *  22x2 + 43x4 = 1\n",
    "    *  -3x1 + 7x2 = 4\n",
    "    *  5x2 + 4x4 = 3\n",
    "    *  11x1+12x2-4x3 = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.36  3.02  1.43 -1.53]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2, -2, 8, 12],\n",
    "              [0, 22 ,0, 43],\n",
    "              [-3, 7 ,0, 0],\n",
    "              [0, 5, 0, 4],\n",
    "              [11, 12, -4, 0]])\n",
    "\n",
    "y = np.array([0, 1, 4, 3, 101])\n",
    "\n",
    "# theta = (X.T * X)^(-1)* X.T * y\n",
    "X = np.matrix(X)\n",
    "theta = np.dot(np.linalg.inv(X.T * X) * X.T, y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–µ—è–∫—ñ –∑–∞–¥–∞—á—ñ –ø—Ä–æ—Ç—è–≥–æ–º —Ç—Ä–∏–º—É:\n",
    "\n",
    "#1. –î–æ —è–∫–æ–≥–æ –∑ —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤ –Ω–∞–ª–µ–∂–∞—Ç—å –Ω–æ–≤—ñ –¥–∞–Ω—ñ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22062422564614886, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1,p2,p3,p4 = stats.norm.pdf(1.75,0,1),stats.norm.pdf(1.75,3,1.5),stats.norm.pdf(1.75,1.5,2),stats.laplace.pdf(1.75,2,2)\n",
    "probs = [p1,p2,p3,p4]\n",
    "max(probs), probs.index(max(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. –ó–Ω–∞–π—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª—É (MVN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,2,1,3,7])\n",
    "x2 = np.array([2,1,2,4,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.array([x1.mean(),x2.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\sum(x_i-m)(x_i-m)^T}{N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix  = np.cov(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–Ω–æ–∂–∏–º–æ –º–∞—Ç—Ä–∏—Ü—ñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#–ó–Ω–∞–π—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤: –≤–µ–∫—Ç–æ—Ä —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ —Ç–∞ –º–∞—Ç—Ä–∏—Ü—ñ—é –∫–æ–≤–∞—Ä—ñ–∞—Ü—ñ—ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov_vect(X):\n",
    "    Y = X-X.mean(axis=1,keepdims=True)\n",
    "    matr = np.zeros(X.shape)\n",
    "    for i in range(Y.shape[0]):\n",
    "        col = np.array(Y[:,i],ndmin=2)\n",
    "        rm = np.dot(col.T,col)\n",
    "        matr+=rm   \n",
    "    return matr/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.22222222, 0.33333333],\n",
       "       [0.22222222, 0.22222222, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.66666667]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_cov_vect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],\n",
    "     [2,3,4],\n",
    "     [7,7,9],\n",
    "     [0, 11, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 2,  3,  4],\n",
       "       [ 7,  7,  9],\n",
       "       [ 0, 11,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.08466181,   0.        ,  14.99604301,   5.75257229,\n",
       "          0.17995579,  15.16359768],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [ 14.99604301,   0.        , 207.3284995 ,  79.53245929,\n",
       "          2.48798727, 209.6450344 ],\n",
       "       [  5.75257229,   0.        ,  79.53245929,  30.5091297 ,\n",
       "          0.95440688,  80.42109602],\n",
       "       [  0.17995579,   0.        ,   2.48798727,   0.95440688,\n",
       "          0.02985639,   2.5157862 ],\n",
       "       [ 15.16359768,   0.        , 209.6450344 ,  80.42109602,\n",
       "          2.5157862 , 211.98745255]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kernel(x):\n",
    "    return x*np.sin(x)+(x**2)/5\n",
    "\n",
    "X = ([1,0,7,6,4,10])\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        arr[i,j]=kernel(X[i])*kernel(X[j])\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  7,  6,  4, 10]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(X,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "gram = pairwise_distances(X,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tan(x**2-2)+np.exp(np.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.370079726523038"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-f(0))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg(x^2 - 2) + exp(sin(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
