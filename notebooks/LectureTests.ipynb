{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Класичний та імовірнисний методи головних компонент. Методи отримання головних компонентів.\n",
    "<br>< -- insert ans here\n",
    "\n",
    "### 2. Метод незалежних компонент. Критерії незалежності компонентів.\n",
    "<br>< -- insert ans here\n",
    "\n",
    "### 3. Застосування марківських моделей в задачах моделювання природних мов.\n",
    "Можемо змоделювати речення у вигляді $P(x_1...x_t) = p(x1)p(x2|x1)p(x3|x1, x2) ... p(xt|x1 ... xt-1)$. Нам потрібно знайти найбільш ймовірну послідовність тегів за даного речення. $у = argmax P(y|x) = argmax p(x, y)$ де $P(x, y) = P(x|y)P(y) = Product from t=1 to T P(x_t|y_t)P(y_t|y_t-1)$ за умови Марківського припущення $p(y) = product from t=1 to T P(y_t|y_t-1)$\n",
    "\n",
    "\n",
    "### 4. Умови існування стаціонарного розподілу для марківських моделей.\n",
    "\n",
    "Мають виконувати 2 умови:<br>\n",
    "\n",
    "* Theorem: Every irreducible (singly connected), aperiodic finite state Markov chain has a limiting distribution, which is equal to pi, its unique stationary distribution.(Кожний непривідний аперіодичний ланцюг Маркова з кінцевою к-тю станів має обмежуючий розподіл,що співпадає з деяким розподілом pi , його єдиним стац. розподілом)<br>\n",
    "* Theorem: Every irreducible (singly connected), ergodic Markov chain has a limiting distribution, which is equal to pi, its unique stationary distribution.<br>\n",
    "\n",
    "\n",
    "### 5. Методи прийняття рішень (inference) з використанням прихованих марківських моделей.\n",
    "\n",
    "### 6. Робастна та гребнева (ridge) регресія. Порівняння з лінійною регресією.\n",
    "\n",
    "### 7. Виведення основного рівняння лінійної регресії.\n",
    "\n",
    "\n",
    "\n",
    "### 8. Поняття ядерних функцій. Вимоги до ядерних функцій (теорема Мерсера).\n",
    "Ядерна функція - дійснозначна функція від двох змінних. Зазвичай функція є симетричною та невідємною, отже може бути інтерпретованою як міра схожості, але не завжди.\n",
    "Теорема Мерсера: якщо матриця Грама є додатньо визначеню, ми можемо порахувати розклад власних векторів як $K = U^{T} * \\lambda * U $ де $\\lambda$ діагональна матриця власних невідємних чисел. Розглядаючи елементи матриці K:\n",
    "     $k_{i,j} = (\\lambda^{1/2} * U[:, i]) ^{T} * (\\lambda^{1/2} * U[:, j])$ Можемо переписати $k_{i,j} = \\phi(x_i)^{T} \\phi(x_j)$. Якщо ядерна функція належить до классу Мерсера,тоді існує функція $\\phi$ така, що: $k(x, x') = \\phi(x)^{T}\\phi(x')$\n",
    "\n",
    "### 9. Відмінності лінійної та логістичної регресії з точки зору вирішеня задачі класифікації.\n",
    "1. Відмінності лінійної та логістичної регресії з точки зору вирішеня задачі класифікації.\n",
    "* Логістична регресія дає на вивід ймовірності (від 0 до 1), лінійна регресія - дійсні числа. \n",
    "* У випадку бінарної класифікації для логістичної регресії маємо відносити новий об'єкт до класу 0, якщо вивід моделі <0.5, інакше відносимо об'єкт до класу 1.\n",
    "* Для лінійної регресії маємо спершу віднайти значення (max-min)/2 (або можливо інший decision boundary), та потім віднести об'єкт до відповідного класу.\n",
    "* Загалом обидва методи відносяться до лінійних класифікаторів та є досить схожими.\n",
    "* Деякі переваги логістичної регресії:\n",
    "    *\tLR models are easy to extend to multi-class classification;\n",
    "    *\tLR model can be easily be extended to handle non-linear decision boundaries by using kernels or by learning features from data.\n",
    "\n",
    "### 10. Метод опорних векторів (Support Vector Machine, SVM). Відмінності від інших методів класифікації даних.\n",
    "\n",
    "### 11. Дерева класифікації та регресії. Особливості, обмеження та переваги.\n",
    "\n",
    "$𝑓(𝐱)=𝔼[𝑦|𝐱]=∑_{𝑚=1}^{𝑀}𝑤_𝑚 𝕀(𝐱∈ℛ_𝑚 ) =∑_{𝑚=1}^{𝑀}(w_𝑚 𝜙(𝐱, 𝐯_𝑚 ))$  де $R_m$ - m-й регіон\n",
    "\n",
    "Переваги: \n",
    "- інтерпретовані\n",
    "- можуть поєднувати дискретні та неперервні значення\n",
    "- нечутливі для монотонної трансформації входу\n",
    "- автоматично проводять відбір змінних\n",
    "- відносно нечутливі до викидів\n",
    "- можуть сприймати пропущені данні\n",
    "\n",
    "Недоліки:\n",
    "- не дуже точно передбачують результат\n",
    "- нестабільні (маленька зміна вхідних даних может вплинути на структуру дерева)\n",
    "\n",
    "### 12. Поняття подільних ядерних функцій. Вимоги до функцій.\n",
    "  \\phi(x1, ..., xn) = \\phi(x1) * ... * \\phi(xn)\\\n",
    "  \n",
    "### 13. Ансамблеві класифікатори. Особливості та приклади.\n",
    "\n",
    "Ансамблеві класифікатори\n",
    "Моделі що агругують комбінації ваг більш простих моделей f(y|x, $\\theta$) = $\\sum$ $weights_i * f_m(y|x)$, де ваги - тренований параметри. Прикладом ансамблевих методів є\n",
    "Random Forest\n",
    "Бустингові дерева\n",
    "Також підвидом ансамблевих моделей можна виділити Stacking, де ми поєднуємо передбачення більш простих моделей для тренування більш складних.\n",
    "\n",
    "### 14. Методи агрегації даних (bagging) при налаштуванні класифікаторів.\n",
    "* bootstrap aggregating (bagging) is a technique to reduce the variance of an estimate to average together many estimates. For example, we can train 𝑀 different trees on different subsets of the data, chosen randomly with replacement, and then compute the ensemble f(x) = sum(f_m(x))/M\n",
    "\n",
    "### 15. Ансамлеві методи підсилення (boosting) класифікаторів.\n",
    "\n",
    "Бустингові класифікатори - жадібні алгоритми, які поєднують в собі більш прості модели за $f(x) = w_0 + sum(w_m * \\phi_m(x)) $ де кожний $\\phi_m$ базовий алгоритм навчання. В залежності від функції втрати існую різні типи бустингових класифікаторів (L2Boosting, Gradient Boosting, AdaBosting, LogitBoosting)\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 1. Задано послідовність вихідних станів марківської моделі:\n",
    "  X = {1, 3, 2, 6, 10, 1, 4, 3, 7, 9, 9}\n",
    "  Загальна кількість станів моделі рівна 10. Розрахувати матрицю переходів (transition matrix) на 4 ітерації.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  2,  6, 10,  1,  4,  3,  7,  9,  9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 3, 2, 6, 10, 1, 4, 3, 7, 9, 9])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_filled(x):\n",
    "    matrix = np.zeros((10, 10))\n",
    "    for i in range(x.shape[0] - 1):\n",
    "        val_1 = x[i]\n",
    "        val_2 = x[i+1]\n",
    "        matrix[val_2 - 1][val_1 - 1] += 1\n",
    "        #print(val_1, val_2)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(matrix, epsilon=1e-10):\n",
    "    row_sums = (matrix + epsilon).sum(axis = 1)\n",
    "    res = matrix / row_sums[:, np.newaxis]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized matrix\n",
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.5 0.  0.  0.5 0.  0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.5 0.  0.5 0. ]\n",
      " [0.  0.  0.  0.  0.  1.  0.  0.  0.  0. ]]\n",
      "Matrix in power of 4\n",
      "[[0.     0.     1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.5    0.     0.     0.     0.5   ]\n",
      " [0.     0.5    0.     0.     0.     0.5    0.     0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.5    0.     0.     0.     0.     0.     0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.     0.5    0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.375  0.     0.125  0.125  0.     0.     0.0625 0.     0.0625 0.25  ]\n",
      " [0.5    0.     0.     0.5    0.     0.     0.     0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "matrix = matrix_filled(x)\n",
    "matrix_norm = normalize_matrix(matrix)\n",
    "print('Normalized matrix')\n",
    "print(matrix_norm)\n",
    "print('Matrix in power of 4')\n",
    "print(np.linalg.matrix_power(matrix_norm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Задано послідовність станів марківської моделі:\n",
    "  X = {2,5,4,7,3,4,2,3,5,4,6,7,7,6,1}\n",
    "  pi = {0.3; 0.1; 0.1; 0.2; 0.1; 0.1; 0.1}\n",
    "  Загальна кількість станів рівна 7. Розрахувати значення елементів вектора стану pi на 3 ітерації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,pi,n = np.array([2,5,4,7,3,4,2,3,5,4,6,7,7,6,1]),np.array([0.3, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1]),7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Задано емпіричні розподіли трьох класів:\n",
    "  X1 = {(1, 3); (2, 4); (3, 5)}\n",
    "  X2 = {(2, 5); (0, 8); (4, 1); (1, 1)}\n",
    "  X3 = {(1, 1); (-5 , 4); (0, 8)}\n",
    "\n",
    "Використовуючи GMM вирішити задачу багатокласової класифікації для нового елемента x = (2, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1, 3], [2, 4], [3, 5]])\n",
    "x2 = np.array([[2, 5], [0, 8], [4, 1],[1, 1]])\n",
    "x3 = np.array([[1, 1], [-5 , 4], [0, 8]])\n",
    "\n",
    "x_new = np.array([2, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(x1, axis=0, keepdims=True)\n",
    "mean_2 = np.mean(x2, axis=0, keepdims=True)\n",
    "mean_3 = np.mean(x3, axis=0, keepdims=True)\n",
    "\n",
    "cov_1 = np.cov(x1)\n",
    "cov_2 = np.cov(x2)\n",
    "cov_3 = np.cov(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== model1 ==\n",
      "Mean:  [[2. 4.]] \n",
      "Cov:  [[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "== model2 ==\n",
      "Mean:  [[1.75 3.75]] \n",
      "Cov:  [[  4.5  12.   -4.5   0. ]\n",
      " [ 12.   32.  -12.    0. ]\n",
      " [ -4.5 -12.    4.5   0. ]\n",
      " [  0.    0.    0.    0. ]]\n",
      "== model3 ==\n",
      "Mean:  [[-1.33333333  4.33333333]] \n",
      "Cov:  [[ 0.   0.   0. ]\n",
      " [ 0.  40.5 36. ]\n",
      " [ 0.  36.  32. ]]\n"
     ]
    }
   ],
   "source": [
    "print('== model1 ==')\n",
    "print('Mean: ', mean_1,'\\nCov: ', cov_1)\n",
    "print('== model2 ==')\n",
    "print('Mean: ', mean_2,'\\nCov: ', cov_2)\n",
    "print('== model3 ==')\n",
    "print('Mean: ', mean_3,'\\nCov: ', cov_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 4. Обчислити перші 2 головні компоненти для заданої вибірки значень: [Залишити 2 головні компоненти (перші 2 рядки) в s, перемножити на інші]\n",
    "  X = {(1,2,3);\n",
    "     (2,3,4);\n",
    "     (7,7,9);\n",
    "     (0, 11, 0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.21299335,  0.11166707,  0.7341609 ,  0.63495832],\n",
       "        [-0.31466555,  0.15717558,  0.5437956 , -0.76194998],\n",
       "        [-0.7774661 ,  0.46334971, -0.40586529,  0.12699166],\n",
       "        [-0.50116454, -0.86494702, -0.02382178,  0.0115447 ]]),\n",
       " array([16.44752767,  8.42106835,  1.25077632]),\n",
       " array([[-0.3820992 , -0.74935615, -0.54080086],\n",
       "        [ 0.4357483 , -0.66216163,  0.60964366],\n",
       "        [-0.8149378 , -0.0027087 ,  0.57954209]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "X = np.array([[1,2,3],\n",
    "              [2,3,4],\n",
    "              [7,7,9],\n",
    "              [0,11,0]])\n",
    "U,s,V=np.linalg.svd(X)\n",
    "\n",
    "U,s,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(U,s,V,n=2):\n",
    "    s[n:]=0\n",
    "    S = np.zeros((U.shape[0],V.shape[0]))\n",
    "    S[:s.shape[0],:s.shape[0]]=np.diag(s)\n",
    "    return U@S@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.74833381,  2.00248732,  2.46782326],\n",
       "       [ 2.55429353,  3.00184237,  3.60581479],\n",
       "       [ 6.58629952,  6.99862494,  9.29420263],\n",
       "       [-0.02428166, 10.99991929,  0.01726787]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct(U,s,V,n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 5. Визначити вектор прихованих факторів (latent variables) \n",
    "за відомою матрицею змішування W та вектором математичного очікування mu. Розглянути випадок, коли вплив помилок відсутній (eps -> 0)\n",
    "  mu = (1, 3, 5, 7)\n",
    "  W = (1, 2, 3, 7, 11)\n",
    "    (3,7,2,3,4)\n",
    "    (9,4,0,0,1)\n",
    "    (1,1,1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00936953  0.29895034 -0.60758983 -1.35412461]\n",
      " [ 0.05029606 -0.65684296  0.17359709  2.05355941]\n",
      " [ 0.0843258   0.30944691  0.46830844 -8.81287848]\n",
      " [-0.00839389  0.11162697  0.19176423 -2.85944018]\n",
      " [-0.11685843 -0.06318127 -0.22607994  3.97288386]]\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([1, 3, 5, 7])\n",
    "W = np.array([[1, 2, 3, 7, 11],\n",
    "              [3, 7, 2, 3, 4],\n",
    "              [9, 4, 0, 0, 1],\n",
    "              [1, 1, 1, 1, 1]])\n",
    "# W*z + mu = epsilon -> 0\n",
    "# WZ = -mu\n",
    "# z = W^(-1) * (-mu)\n",
    "np.set_printoptions(suppress=True)\n",
    "z = np.linalg.pinv(W) * (-mu)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 6. Вирішити систему лінійних арифметичних рівнянь:\n",
    "  (1) x1 + 4x2 + x3 = 0\n",
    "  (2) 8x2 - 3x3 = 5\n",
    "  (3) x1 + 78x3 = 21\n",
    "  (4) 3x1 + 2x2 = 4\n",
    "  (5) 6x1+x2+x3 = 77\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.2248782 , 11.04936545,  0.97260676])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1,4,1],\n",
    "              [0,8,-3],\n",
    "              [1,0,78],\n",
    "              [3,2,0],\n",
    "              [6,1,1]\n",
    "             ])\n",
    "y = np.array([0,5,21,4,77])\n",
    "\n",
    "\n",
    "lr = LinearRegression().fit(X,y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Вирішити задачу багатокласової класифікації для виміру x={1, 2.5, 7} при відомих густинах розподілу класів (модель GMM):\n",
    "  C1 = {(1, 4, 7), (2, 8, 9)}\n",
    "  C2 = {(1, 1, 0), (8, 10, 28)}\n",
    "  C3 = {(0, 7, 11), (7, 5, 15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov_vect(X):\n",
    "    Y = X-X.mean(axis=1,keepdims=True)\n",
    "    matr = np.zeros(X.shape)\n",
    "    for i in range(Y.shape[0]):\n",
    "        col = np.array(Y[:,i],ndmin=2)\n",
    "        rm = np.dot(col.T,col)\n",
    "        matr+=rm   \n",
    "    return matr/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1, 4, 7], [2, 8, 9]])\n",
    "x2 = np.array([[1, 1, 0], [8, 10, 28]])\n",
    "x3 = np.array([[0, 7, 11], [7, 5, 15]])\n",
    "\n",
    "x_new = np.array([1, 2.5, 7])\n",
    "\n",
    "mean_1 = np.mean(x1, axis=0, keepdims=True)\n",
    "mean_2 = np.mean(x2, axis=0, keepdims=True)\n",
    "mean_3 = np.mean(x3, axis=0, keepdims=True)\n",
    "\n",
    "cov_1 = np.cov(x1)\n",
    "cov_2 = np.cov(x2)\n",
    "cov_3 = np.cov(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 8, 9]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,2) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-d89246eef87f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc_cov_vect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-1d3eaa382ade>\u001b[0m in \u001b[0;36mcalc_cov_vect\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mrm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmatr\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mrm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,2) (2,3) "
     ]
    }
   ],
   "source": [
    "calc_cov_vect(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== model1 ==\n",
      "Mean:  [[1.5 6.  8. ]] \n",
      "Cov:  [[ 9.         10.5       ]\n",
      " [10.5        14.33333333]]\n",
      "== model2 ==\n",
      "Mean:  [[ 4.5  5.5 14. ]] \n",
      "Cov:  [[  0.33333333  -6.33333333]\n",
      " [ -6.33333333 121.33333333]]\n",
      "== model3 ==\n",
      "Mean:  [[ 3.5  6.  13. ]] \n",
      "Cov:  [[31. 19.]\n",
      " [19. 28.]]\n"
     ]
    }
   ],
   "source": [
    "print('== model1 ==')\n",
    "print('Mean: ', mean_1,'\\nCov: ', cov_1)\n",
    "print('== model2 ==')\n",
    "print('Mean: ', mean_2,'\\nCov: ', cov_2)\n",
    "print('== model3 ==')\n",
    "print('Mean: ', mean_3,'\\nCov: ', cov_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 6. , 8. ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.        , 10.5       ],\n",
       "       [10.5       , 14.33333333]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension mismatch: array 'cov' is of shape (2, 2), but 'mean' is a vector of length 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b110c99926fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    361\u001b[0m         return multivariate_normal_frozen(mean, cov,\n\u001b[0;32m    362\u001b[0m                                           \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                                           seed=seed)\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         self.dim, self.mean, self.cov = self._dist._process_parameters(\n\u001b[1;32m--> 735\u001b[1;33m                                                             None, mean, cov)\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmaxpts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m_process_parameters\u001b[1;34m(self, dim, mean, cov)\u001b[0m\n\u001b[0;32m    419\u001b[0m                        \" but 'mean' is a vector of length %d.\")\n\u001b[0;32m    420\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             raise ValueError(\"Array 'cov' must be at most two-dimensional,\"\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension mismatch: array 'cov' is of shape (2, 2), but 'mean' is a vector of length 3."
     ]
    }
   ],
   "source": [
    "stats.multivariate_normal(mean_1[0], cov_1).pdf(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Задано послідовність станів марківської моделі першого порядку:\n",
    "  X = {1, 7, 5, 4, 3, 10, 1, 1, 5, 7, 5, 6, 1}\n",
    "  Загальна кількість станів моделі рівна 10. Розрахувати матрицю переходів (transition matrix) на 3 ітерації.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,n = np.array([1, 7, 5, 4, 3, 10, 1, 1, 5, 7, 5, 6, 1]),10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = matrix_filled(X)\n",
    "normalized_x = normalize_matrix(x)\n",
    "np.linalg.matrix_power(normalized_x,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 9. Обчислити матрицю Грама для ядерної функції k(x) = xsin(x) + x^2 / 5 \n",
    "на множині X = {1, 0, 7, 6, 4, 10}. Аргумент функції sin(x) задано в радіанах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x):\n",
    "    return x * np.sin(x) + (x ** 2) / 5\n",
    "\n",
    "X = np.array([1,0,7,6,4,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.08466181   0.          14.99604301   5.75257229   0.17995579\n",
      "   15.16359768]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [ 14.99604301   0.         207.3284995   79.53245929   2.48798727\n",
      "  209.6450344 ]\n",
      " [  5.75257229   0.          79.53245929  30.5091297    0.95440688\n",
      "   80.42109602]\n",
      " [  0.17995579   0.           2.48798727   0.95440688   0.02985639\n",
      "    2.5157862 ]\n",
      " [ 15.16359768   0.         209.6450344   80.42109602   2.5157862\n",
      "  211.98745255]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros((6, 6))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        arr[i, j] = kernel(X[i]) * kernel(X[j])\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 10. Перевірити, чи є відносить задана ядерна функція k(x) = exp{sin(x) + 1} + xtan(x) до класу ядерних функцій Мерсена. \n",
    "Перевірку виконати на множині X={7, 6, 2, 1, 0, 4, 6, 9}. Аргументи тригонометричних функцій задано в радіанах.\n",
    "\n",
    "Маємо сформувати матрицю грама та перевірити, що вона positive definite. Якщо вона буде вона positive definite, ядерна ф-ція відноситься до класу ядерних ф-й Мерсена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([7,6,2,1,0,4,6,9])\n",
    "def k(x):\n",
    "    return np.exp(np.sin(x)+1) + x*np.tan(x)\n",
    "\n",
    "def form_gram_matrix(X,kernel):\n",
    "    n = X.shape[0]\n",
    "    K = np.array([[kernel(X[i])*kernel(X[j]) for i in range(n)] for j in range(n)])\n",
    "    return K\n",
    "\n",
    "def check_positive_definite(K,X):\n",
    "    return X.T@K@X \n",
    "\n",
    "def check_kernel_function(X,kernel,print_gram=False):\n",
    "    K = form_gram_matrix(X,kernel)\n",
    "    \n",
    "    if print_gram:\n",
    "        print(f'Gram matrix:\\n{K}')\n",
    "    \n",
    "    prod = check_positive_definite(K,X)\n",
    "    print(f'X.T@K@X={prod}')\n",
    "    if prod>0:\n",
    "        return \"kernel function is positive-definite\"\n",
    "    return \"kernel function isn't positive-definite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram matrix:\n",
      "[[128.68   3.51  26.98  89.2   30.84  67.     3.51   0.38]\n",
      " [  3.51   0.1    0.74   2.43   0.84   1.83   0.1    0.01]\n",
      " [ 26.98   0.74   5.66  18.7    6.46  14.05   0.74   0.08]\n",
      " [ 89.2    2.43  18.7   61.83  21.37  46.44   2.43   0.27]\n",
      " [ 30.84   0.84   6.46  21.37   7.39  16.06   0.84   0.09]\n",
      " [ 67.     1.83  14.05  46.44  16.06  34.89   1.83   0.2 ]\n",
      " [  3.51   0.1    0.74   2.43   0.84   1.83   0.1    0.01]\n",
      " [  0.38   0.01   0.08   0.27   0.09   0.2    0.01   0.  ]]\n",
      "X.T@K@X=14321.124233689508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kernel function is positive-definite'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_kernel_function(X,k,print_gram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 11. Перевірити, чи належить задана ядерна функція k(x) = ln(1 + exp(-x) + tg(x)^2) до класу ядерних функцій Мерсена. \n",
    "  Перевірку виконати на множині X={1,9,7,5,3,2}. Аргументи тригонометричних функцій задано в радіанах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,9,7,5,3,2])\n",
    "def k(x):\n",
    "    return np.log(1+np.exp(-x)+np.tan(x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram matrix:\n",
      "[[1.78 0.25 0.75 3.36 0.09 2.37]\n",
      " [0.25 0.03 0.11 0.47 0.01 0.33]\n",
      " [0.75 0.11 0.32 1.43 0.04 1.  ]\n",
      " [3.36 0.47 1.43 6.35 0.17 4.48]\n",
      " [0.09 0.01 0.04 0.17 0.   0.12]\n",
      " [2.37 0.33 1.   4.48 0.12 3.16]]\n",
      "X.T@K@X=544.14218243972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kernel function is positive-definite'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_kernel_function(X,k,print_gram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 12. Визначити вектор прихованих факторів (latent variables) за відомою матрицею змішування W та вектором математичного очікування mu. \n",
    "  Розглянути випадок, коли вплив помилок відсутній (eps -> 0)\n",
    "  mu = (4,5,3,6)\n",
    "  W = (1,2,3)\n",
    "    (95,7,0)\n",
    "    (1,2,5)\n",
    "    (0,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28051002 -0.05464481 -0.09562842 -0.30601093]\n",
      " [-3.80692168  0.0273224   1.29781421  4.15300546]\n",
      " [ 1.33333333 -0.         -1.         -2.        ]]\n"
     ]
    }
   ],
   "source": [
    "W =np.array([[1,2,3],\n",
    "    [95,7,0],\n",
    "    [1,2,5],\n",
    "    [0,0,1]])\n",
    "mu = np.array([4,5,3,6])\n",
    "z = np.linalg.pinv(W) * (-mu)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 13. Обчислити перші 3 головні компоненти для заданої вибірки значень:\n",
    "  X = {(1,2,3,8);\n",
    "     (5,3,6,2);\n",
    "     (7,5,6,8);\n",
    "     (0,0,0,1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,8],\n",
    "     [5,3,6,2],\n",
    "     [7,5,6,8],\n",
    "     [0,0,0,1]])\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "u, s, vh = np.linalg.svd(X, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45103945,  0.74955999,  0.47409566, -0.09978246],\n",
       "       [-0.45211097, -0.64452157,  0.60908097,  0.09595827],\n",
       "       [-0.76864884, -0.06716484, -0.63454343, -0.04497204],\n",
       "       [-0.03657932,  0.13505797, -0.04010375,  0.98934978]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.10171748,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  5.64592816,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.62212023,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[n_components:] = 0\n",
    "np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47317681, -0.35678615, -0.50741554, -0.62556919],\n",
       "       [-0.52129636, -0.13642911, -0.35803476,  0.76252759],\n",
       "       [-0.56857901, -0.24491583,  0.78262522, -0.0650531 ],\n",
       "       [ 0.42552523, -0.8911268 ,  0.04287594,  0.15160132]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.00650628,  1.98637468,  3.00065557,  8.00231798],\n",
       "        [ 4.99374308,  3.01310313,  5.99936955,  1.99777085],\n",
       "        [ 7.00293239,  4.99385906,  6.00029547,  8.00104472],\n",
       "        [-0.06451019,  0.135096  , -0.00650005,  0.97701704]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconst = np.matrix(u) * np.diag(s) * np.matrix(vh)\n",
    "reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Обчислити антиградіент квадратичної функції втрат в точці x = 0, y = 1:\n",
    "  loss = 1/2 * (y - f(x)) ^2\n",
    "  f(x) = tg(x^2 - 2) + exp(sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tan(x**2-2)+np.exp(np.sin(x))\n",
    "\n",
    "def loss(x,y):\n",
    "    return 0.5*(y-f(x)) **2\n",
    "\n",
    "x,y=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 15. Вирішити систему лінійних арифметичних рівнянь:\n",
    "Використовуємо лін рег тому що маємо рівнянь більше ніж змінних\n",
    "\n",
    "    *  2x1 - 2x2 + 8x3 + 12x4 = 0\n",
    "    *  22x2 + 43x4 = 1\n",
    "    *  -3x1 + 7x2 = 4\n",
    "    *  5x2 + 4x4 = 3\n",
    "    *  11x1+12x2-4x3 = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.46796206,  5.39555864,  5.13231552, -2.40319223])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[2,-2,8,12],\n",
    "                [0,22,0,43],\n",
    "                [-3,7,0,0],\n",
    "                [0,5,0,4],\n",
    "                [11,12,-4,0]])\n",
    "y = np.array([0,1,4,3,101])\n",
    "\n",
    "lr = LinearRegression().fit(X,y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деякі задачі протягом триму:\n",
    "\n",
    "#1. До якого з розподілів належать нові дані?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22062422564614886, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1,p2,p3,p4 = stats.norm.pdf(1.75,0,1),stats.norm.pdf(1.75,3,1.5),stats.norm.pdf(1.75,1.5,2),stats.laplace.pdf(1.75,2,2)\n",
    "probs = [p1,p2,p3,p4]\n",
    "max(probs), probs.index(max(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Знайти параметри розподілу (MVN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,2,1,3,7])\n",
    "x2 = np.array([2,1,2,4,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.array([x1.mean(),x2.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\sum(x_i-m)(x_i-m)^T}{N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix  = np.cov(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множимо матриці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Знайти параметри розподілів: вектор середнього та матрицію коваріації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov_vect(X):\n",
    "    Y = X-X.mean(axis=1,keepdims=True)\n",
    "    matr = np.zeros(X.shape)\n",
    "    for i in range(Y.shape[0]):\n",
    "        col = np.array(Y[:,i],ndmin=2)\n",
    "        rm = np.dot(col.T,col)\n",
    "        matr+=rm   \n",
    "    return matr/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.22222222, 0.33333333],\n",
       "       [0.22222222, 0.22222222, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.66666667]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_cov_vect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],\n",
    "     [2,3,4],\n",
    "     [7,7,9],\n",
    "     [0, 11, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 2,  3,  4],\n",
       "       [ 7,  7,  9],\n",
       "       [ 0, 11,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.08466181,   0.        ,  14.99604301,   5.75257229,\n",
       "          0.17995579,  15.16359768],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [ 14.99604301,   0.        , 207.3284995 ,  79.53245929,\n",
       "          2.48798727, 209.6450344 ],\n",
       "       [  5.75257229,   0.        ,  79.53245929,  30.5091297 ,\n",
       "          0.95440688,  80.42109602],\n",
       "       [  0.17995579,   0.        ,   2.48798727,   0.95440688,\n",
       "          0.02985639,   2.5157862 ],\n",
       "       [ 15.16359768,   0.        , 209.6450344 ,  80.42109602,\n",
       "          2.5157862 , 211.98745255]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kernel(x):\n",
    "    return x*np.sin(x)+(x**2)/5\n",
    "\n",
    "X = ([1,0,7,6,4,10])\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        arr[i,j]=kernel(X[i])*kernel(X[j])\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  7,  6,  4, 10]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(X,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "gram = pairwise_distances(X,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tan(x**2-2)+np.exp(np.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.370079726523038"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-f(0))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg(x^2 - 2) + exp(sin(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
