{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Класичний та імовірнисний методи головних компонент. Методи отримання головних компонентів.\n",
    "\n",
    "\n",
    "* PCA may also be solved via an SVD composition: any real NxD matrix X can be decomposed as $X_{NxD}=U_{NxN}* S_{NxD} * V_{DxD}^T$, where $U$ and $V$ are matrices with orthonormal columns, S - matrix of zeros, containing $r = min(N,D)$ singular values $\\sigma_i>0$ on the main diagonal. Columns of U(V) are left(right) singular vectors\n",
    "\n",
    "* PCA may be solved via EM-algorithm, with: $$E-step: Z=(W^TW)^-1W^TX$$ $$M-step: W =XZ^T(ZZ^T)^-1 $$, where $Z_{LxN}$ stands for a matrix storing the posterior means  along its columns; \n",
    "Some advantages of EM-algo:\n",
    "    *  can be faster\n",
    "    *  can handle missing data in a simple way\n",
    "\n",
    "### 2. Метод незалежних компонент. Критерії незалежності компонентів.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Застосування марківських моделей в задачах моделювання природних мов.\n",
    "Можемо змоделювати речення у вигляді $P(x_1...x_t) = p(x1)p(x2|x1)p(x3|x1, x2) ... p(xt|x1 ... xt-1)$. Нам потрібно знайти найбільш ймовірну послідовність тегів за даного речення. $у = argmax P(y|x) = argmax p(x, y)$ де $P(x, y) = P(x|y)P(y) = Product from t=1 to T P(x_t|y_t)P(y_t|y_t-1)$ за умови Марківського припущення $p(y) = product from t=1 to T P(y_t|y_t-1)$\n",
    "\n",
    "\n",
    "### 4. Умови існування стаціонарного розподілу для марківських моделей.\n",
    "\n",
    "Мають виконувати 2 умови:<br>\n",
    "\n",
    "* Theorem: Every irreducible (singly connected), aperiodic finite state Markov chain has a limiting distribution, which is equal to pi, its unique stationary distribution.(Кожний непривідний аперіодичний ланцюг Маркова з кінцевою к-тю станів має обмежуючий розподіл,що співпадає з деяким розподілом pi , його єдиним стац. розподілом)<br>\n",
    "* Theorem: Every irreducible (singly connected), ergodic Markov chain has a limiting distribution, which is equal to pi, its unique stationary distribution.<br>\n",
    "\n",
    "\n",
    "### 5. Методи прийняття рішень (inference) з використанням прихованих марківських моделей.\n",
    "L5, slide 15\n",
    "\n",
    "### 6. Робастна та гребнева (ridge) регресія. Порівняння з лінійною регресією.\n",
    "\n",
    "\n",
    "\n",
    "### 7. Виведення основного рівняння лінійної регресії.\n",
    "\n",
    "\n",
    "\n",
    "### 8. Поняття ядерних функцій. Вимоги до ядерних функцій (теорема Мерсера).\n",
    "Ядерна функція - дійснозначна функція від двох змінних. Зазвичай функція є симетричною та невідємною, отже може бути інтерпретованою як міра схожості, але не завжди.\n",
    "Теорема Мерсера: якщо матриця Грама є додатньо визначеню, ми можемо порахувати розклад власних векторів як $K = U^{T} * \\lambda * U $ де $\\lambda$ діагональна матриця власних невідємних чисел. Розглядаючи елементи матриці K:\n",
    "     $k_{i,j} = (\\lambda^{1/2} * U[:, i]) ^{T} * (\\lambda^{1/2} * U[:, j])$ Можемо переписати $k_{i,j} = \\phi(x_i)^{T} \\phi(x_j)$. Якщо ядерна функція належить до классу Мерсера,тоді існує функція $\\phi$ така, що: $k(x, x') = \\phi(x)^{T}\\phi(x')$\n",
    "\n",
    "### 9. Відмінності лінійної та логістичної регресії з точки зору вирішеня задачі класифікації.\n",
    "1. Відмінності лінійної та логістичної регресії з точки зору вирішеня задачі класифікації.\n",
    "* Логістична регресія дає на вивід ймовірності (від 0 до 1), лінійна регресія - дійсні числа. \n",
    "* У випадку бінарної класифікації для логістичної регресії маємо відносити новий об'єкт до класу 0, якщо вивід моделі <0.5, інакше відносимо об'єкт до класу 1.\n",
    "* Для лінійної регресії маємо спершу віднайти значення (max-min)/2 (або можливо інший decision boundary), та потім віднести об'єкт до відповідного класу.\n",
    "* Загалом обидва методи відносяться до лінійних класифікаторів та є досить схожими.\n",
    "* Деякі переваги логістичної регресії:\n",
    "    *\tLR models are easy to extend to multi-class classification;\n",
    "    *\tLR model can be easily be extended to handle non-linear decision boundaries by using kernels or by learning features from data.\n",
    "\n",
    "### 10. Метод опорних векторів (Support Vector Machine, SVM). Відмінності від інших методів класифікації даних.\n",
    "\n",
    "Метод опорних векторів (англ. SVM, support vector machine) — набір алгоритмів машинного навчання з учителем,\n",
    "що використовуються для задач класифікації та регресійного аналізу. \n",
    "Ключові властивості: 1) ядерний метод для запобігання недонавчання (underfitting); 2) принцип розрідженості та 3) принцип великої грані (large margin) для запобігання перенавчання.\n",
    "\n",
    "### 11. Дерева класифікації та регресії. Особливості, обмеження та переваги.\n",
    "\n",
    "$𝑓(𝐱)=𝔼[𝑦|𝐱]=∑_{𝑚=1}^{𝑀}𝑤_𝑚 𝕀(𝐱∈ℛ_𝑚 ) =∑_{𝑚=1}^{𝑀}(w_𝑚 𝜙(𝐱, 𝐯_𝑚 ))$  де $R_m$ - m-й регіон\n",
    "\n",
    "Переваги: \n",
    "- інтерпретовані\n",
    "- можуть поєднувати дискретні та неперервні значення\n",
    "- нечутливі для монотонної трансформації входу\n",
    "- автоматично проводять відбір змінних\n",
    "- відносно нечутливі до викидів\n",
    "- можуть сприймати пропущені данні\n",
    "\n",
    "Недоліки:\n",
    "- не дуже точно передбачують результат\n",
    "- нестабільні (маленька зміна вхідних даних может вплинути на структуру дерева)\n",
    "\n",
    "### 12. Поняття подільних ядерних функцій. Вимоги до функцій.\n",
    "  $\\phi(x1, ..., xn) = \\phi(x1) * ... * \\phi(xn)\\$\n",
    "  \n",
    "### 13. Ансамблеві класифікатори. Особливості та приклади.\n",
    "\n",
    "Ансамблеві класифікатори\n",
    "Моделі що агругують комбінації ваг більш простих моделей f(y|x, $\\theta$) = $\\sum$ $weights_i * f_m(y|x)$, де ваги - тренований параметри. Прикладом ансамблевих методів є\n",
    "Random Forest\n",
    "Бустингові дерева\n",
    "Також підвидом ансамблевих моделей можна виділити Stacking, де ми поєднуємо передбачення більш простих моделей для тренування більш складних.\n",
    "\n",
    "### 14. Методи агрегації даних (bagging) при налаштуванні класифікаторів.\n",
    "* bootstrap aggregating (bagging) is a technique to reduce the variance of an estimate to average together many estimates. For example, we can train 𝑀 different trees on different subsets of the data, chosen randomly with replacement, and then compute the ensemble f(x) = sum(f_m(x))/M\n",
    "\n",
    "### 15. Ансамлеві методи підсилення (boosting) класифікаторів.\n",
    "\n",
    "Бустингові класифікатори - жадібні алгоритми, які поєднують в собі більш прості модели за $f(x) = w_0 + sum(w_m * \\phi_m(x)) $ де кожний $\\phi_m$ базовий алгоритм навчання. В залежності від функції втрати існую різні типи бустингових класифікаторів (L2Boosting, Gradient Boosting, AdaBosting, LogitBoosting)\n",
    "![image.png](attachment:image.png)![image.png](attachment:image.png)![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 1. Задано послідовність вихідних станів марківської моделі:\n",
    "  X = {1, 3, 2, 6, 10, 1, 4, 3, 7, 9, 9}\n",
    "  Загальна кількість станів моделі рівна 10. Розрахувати матрицю переходів (transition matrix) на 4 ітерації.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  2,  6, 10,  1,  4,  3,  7,  9,  9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 3, 2, 6, 10, 1, 4, 3, 7, 9, 9])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_filled(x):\n",
    "    matrix = np.zeros((10, 10))\n",
    "    for i in range(x.shape[0] - 1):\n",
    "        val_1 = x[i]\n",
    "        val_2 = x[i+1]\n",
    "        matrix[val_2 - 1][val_1 - 1] += 1\n",
    "        #print(val_1, val_2)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(matrix, epsilon=1e-10):\n",
    "    row_sums = (matrix + epsilon).sum(axis = 1)\n",
    "    res = matrix / row_sums[:, np.newaxis]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized matrix\n",
      "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  1. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.5 0.  0.  0.5 0.  0.  0.  0.  0.  0. ]\n",
      " [1.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  1.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  1.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0.  0.  0.  0.5 0.  0.5 0. ]\n",
      " [0.  0.  0.  0.  0.  1.  0.  0.  0.  0. ]]\n",
      "Matrix in power of 4\n",
      "[[0.     0.     1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.5    0.     0.     0.     0.5   ]\n",
      " [0.     0.5    0.     0.     0.     0.5    0.     0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.5    0.     0.     0.     0.     0.     0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.     0.5    0.     0.     0.     0.5   ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.375  0.     0.125  0.125  0.     0.     0.0625 0.     0.0625 0.25  ]\n",
      " [0.5    0.     0.     0.5    0.     0.     0.     0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "matrix = matrix_filled(x)\n",
    "matrix_norm = normalize_matrix(matrix)\n",
    "print('Normalized matrix')\n",
    "print(matrix_norm)\n",
    "print('Matrix in power of 4')\n",
    "print(np.linalg.matrix_power(matrix_norm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Задано послідовність станів марківської моделі:\n",
    "  X = {2,5,4,7,3,4,2,3,5,4,6,7,7,6,1}\n",
    "  pi = {0.3; 0.1; 0.1; 0.2; 0.1; 0.1; 0.1}\n",
    "  Загальна кількість станів рівна 7. Розрахувати значення елементів вектора стану pi на 3 ітерації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,pi,n = np.array([2,5,4,7,3,4,2,3,5,4,6,7,7,6,1]),np.array([0.3, 0.1, 0.1, 0.2, 0.1, 0.1, 0.1]),7\n",
    "\n",
    "n_states = 7\n",
    "n_iterations = 3\n",
    "\n",
    "matrix = matrix_filled(x, n_states)\n",
    "matrix_norm = normalize_matrix(matrix)\n",
    "matrix_norm2 = np.linalg.matrix_power(matrix_norm, n_iterations)\n",
    "pi2 = np.dot(pi,matrix_norm)\n",
    "pi3 = np.dot(pi2,matrix_norm2)\n",
    "print(pi3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Задано емпіричні розподіли трьох класів:\n",
    "  X1 = {(1, 3); (2, 4); (3, 5)}\n",
    "  X2 = {(2, 5); (0, 8); (4, 1); (1, 1)}\n",
    "  X3 = {(1, 1); (-5 , 4); (0, 8)}\n",
    "\n",
    "Використовуючи GMM вирішити задачу багатокласової класифікації для нового елемента x = (2, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1, 3], [2, 4], [3, 5]])\n",
    "x2 = np.array([[2, 5], [0, 8], [4, 1],[1, 1]])\n",
    "x3 = np.array([[1, 1], [-5 , 4], [0, 8]])\n",
    "\n",
    "x_new = np.array([2, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(x1, axis=0, keepdims=True)\n",
    "mean_2 = np.mean(x2, axis=0, keepdims=True)\n",
    "mean_3 = np.mean(x3, axis=0, keepdims=True)\n",
    "\n",
    "cov_1 = np.cov(x1)\n",
    "cov_2 = np.cov(x2)\n",
    "cov_3 = np.cov(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== model1 ==\n",
      "Mean:  [[2. 4.]] \n",
      "Cov:  [[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n",
      "== model2 ==\n",
      "Mean:  [[1.75 3.75]] \n",
      "Cov:  [[  4.5  12.   -4.5   0. ]\n",
      " [ 12.   32.  -12.    0. ]\n",
      " [ -4.5 -12.    4.5   0. ]\n",
      " [  0.    0.    0.    0. ]]\n",
      "== model3 ==\n",
      "Mean:  [[-1.33333333  4.33333333]] \n",
      "Cov:  [[ 0.   0.   0. ]\n",
      " [ 0.  40.5 36. ]\n",
      " [ 0.  36.  32. ]]\n"
     ]
    }
   ],
   "source": [
    "print('== model1 ==')\n",
    "print('Mean: ', mean_1,'\\nCov: ', cov_1)\n",
    "print('== model2 ==')\n",
    "print('Mean: ', mean_2,'\\nCov: ', cov_2)\n",
    "print('== model3 ==')\n",
    "print('Mean: ', mean_3,'\\nCov: ', cov_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 4. Обчислити перші 2 головні компоненти для заданої вибірки значень: [Залишити 2 головні компоненти (перші 2 рядки) в s, перемножити на інші]\n",
    "  X = {(1,2,3);\n",
    "     (2,3,4);\n",
    "     (7,7,9);\n",
    "     (0, 11, 0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.21299335,  0.11166707,  0.7341609 ,  0.63495832],\n",
       "        [-0.31466555,  0.15717558,  0.5437956 , -0.76194998],\n",
       "        [-0.7774661 ,  0.46334971, -0.40586529,  0.12699166],\n",
       "        [-0.50116454, -0.86494702, -0.02382178,  0.0115447 ]]),\n",
       " array([16.44752767,  8.42106835,  1.25077632]),\n",
       " array([[-0.3820992 , -0.74935615, -0.54080086],\n",
       "        [ 0.4357483 , -0.66216163,  0.60964366],\n",
       "        [-0.8149378 , -0.0027087 ,  0.57954209]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "X = np.array([[1,2,3],\n",
    "              [2,3,4],\n",
    "              [7,7,9],\n",
    "              [0,11,0]])\n",
    "U,s,V=np.linalg.svd(X)\n",
    "\n",
    "U,s,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(U,s,V,n=2):\n",
    "    s[n:]=0\n",
    "    S = np.zeros((U.shape[0],V.shape[0]))\n",
    "    S[:s.shape[0],:s.shape[0]]=np.diag(s)\n",
    "    return U@S@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.74833381,  2.00248732,  2.46782326],\n",
       "       [ 2.55429353,  3.00184237,  3.60581479],\n",
       "       [ 6.58629952,  6.99862494,  9.29420263],\n",
       "       [-0.02428166, 10.99991929,  0.01726787]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruct(U,s,V,n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 5. Визначити вектор прихованих факторів (latent variables) \n",
    "за відомою матрицею змішування W та вектором математичного очікування mu. Розглянути випадок, коли вплив помилок відсутній (eps -> 0)\n",
    "  mu = (1, 3, 5, 7)\n",
    "  W = (1, 2, 3, 7, 11)\n",
    "    (3,7,2,3,4)\n",
    "    (9,4,0,0,1)\n",
    "    (1,1,1,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.67  1.62 -7.95 -2.56  3.57]\n"
     ]
    }
   ],
   "source": [
    "mu = np.array([1, 3, 5, 7])\n",
    "W = np.array([[1, 2, 3, 7, 11],\n",
    "              [3, 7, 2, 3, 4],\n",
    "              [9, 4, 0, 0, 1],\n",
    "              [1, 1, 1, 1, 1]])\n",
    "# W*z + mu = epsilon -> 0\n",
    "# WZ = -mu\n",
    "# z = W^(-1) * (-mu)\n",
    "np.set_printoptions(suppress=True)\n",
    "z = np.dot(np.linalg.pinv(W),(-mu))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 6. Вирішити систему лінійних арифметичних рівнянь:\n",
    "  (1) x1 + 4x2 + x3 = 0\n",
    "  (2) 8x2 - 3x3 = 5\n",
    "  (3) x1 + 78x3 = 21\n",
    "  (4) 3x1 + 2x2 = 4\n",
    "  (5) 6x1+x2+x3 = 77\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.2248782 , 11.04936545,  0.97260676])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1,4,1],\n",
    "              [0,8,-3],\n",
    "              [1,0,78],\n",
    "              [3,2,0],\n",
    "              [6,1,1]\n",
    "             ])\n",
    "y = np.array([0,5,21,4,77])\n",
    "\n",
    "\n",
    "lr = LinearRegression().fit(X,y)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Вирішити задачу багатокласової класифікації для виміру x={1, 2.5, 7} при відомих густинах розподілу класів (модель GMM):\n",
    "  C1 = {(1, 4, 7), (2, 8, 9)}\n",
    "  C2 = {(1, 1, 0), (8, 10, 28)}\n",
    "  C3 = {(0, 7, 11), (7, 5, 15)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov_vect(X):\n",
    "    Y = X-X.mean(axis=1,keepdims=True)\n",
    "    matr = np.zeros(X.shape)\n",
    "    for i in range(Y.shape[0]):\n",
    "        col = np.array(Y[:,i],ndmin=2)\n",
    "        rm = np.dot(col.T,col)\n",
    "        matr+=rm   \n",
    "    return matr/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1, 4, 7], [2, 8, 9]])\n",
    "x2 = np.array([[1, 1, 0], [8, 10, 28]])\n",
    "x3 = np.array([[0, 7, 11], [7, 5, 15]])\n",
    "\n",
    "x_new = np.array([1, 2.5, 7])\n",
    "\n",
    "mean_1 = np.mean(x1, axis=0, keepdims=True)\n",
    "mean_2 = np.mean(x2, axis=0, keepdims=True)\n",
    "mean_3 = np.mean(x3, axis=0, keepdims=True)\n",
    "\n",
    "cov_1 = np.cov(x1)\n",
    "cov_2 = np.cov(x2)\n",
    "cov_3 = np.cov(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 8, 9]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,2) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-d89246eef87f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc_cov_vect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-1d3eaa382ade>\u001b[0m in \u001b[0;36mcalc_cov_vect\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mrm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmatr\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mrm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,2) (2,3) "
     ]
    }
   ],
   "source": [
    "calc_cov_vect(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== model1 ==\n",
      "Mean:  [[1.5 6.  8. ]] \n",
      "Cov:  [[ 9.         10.5       ]\n",
      " [10.5        14.33333333]]\n",
      "== model2 ==\n",
      "Mean:  [[ 4.5  5.5 14. ]] \n",
      "Cov:  [[  0.33333333  -6.33333333]\n",
      " [ -6.33333333 121.33333333]]\n",
      "== model3 ==\n",
      "Mean:  [[ 3.5  6.  13. ]] \n",
      "Cov:  [[31. 19.]\n",
      " [19. 28.]]\n"
     ]
    }
   ],
   "source": [
    "print('== model1 ==')\n",
    "print('Mean: ', mean_1,'\\nCov: ', cov_1)\n",
    "print('== model2 ==')\n",
    "print('Mean: ', mean_2,'\\nCov: ', cov_2)\n",
    "print('== model3 ==')\n",
    "print('Mean: ', mean_3,'\\nCov: ', cov_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 6. , 8. ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.        , 10.5       ],\n",
       "       [10.5       , 14.33333333]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension mismatch: array 'cov' is of shape (2, 2), but 'mean' is a vector of length 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b110c99926fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, mean, cov, allow_singular, seed)\u001b[0m\n\u001b[0;32m    361\u001b[0m         return multivariate_normal_frozen(mean, cov,\n\u001b[0;32m    362\u001b[0m                                           \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                                           seed=seed)\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mean, cov, allow_singular, seed, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m         self.dim, self.mean, self.cov = self._dist._process_parameters(\n\u001b[1;32m--> 735\u001b[1;33m                                                             None, mean, cov)\n\u001b[0m\u001b[0;32m    736\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_PSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_singular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmaxpts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexa\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m_process_parameters\u001b[1;34m(self, dim, mean, cov)\u001b[0m\n\u001b[0;32m    419\u001b[0m                        \" but 'mean' is a vector of length %d.\")\n\u001b[0;32m    420\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             raise ValueError(\"Array 'cov' must be at most two-dimensional,\"\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension mismatch: array 'cov' is of shape (2, 2), but 'mean' is a vector of length 3."
     ]
    }
   ],
   "source": [
    "stats.multivariate_normal(mean_1[0], cov_1).pdf(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 8. Задано послідовність станів марківської моделі першого порядку:\n",
    "  X = {1, 7, 5, 4, 3, 10, 1, 1, 5, 7, 5, 6, 1}\n",
    "  Загальна кількість станів моделі рівна 10. Розрахувати матрицю переходів (transition matrix) на 3 ітерації.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,n = np.array([1, 7, 5, 4, 3, 10, 1, 1, 5, 7, 5, 6, 1]),10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0.5, 0. , 0. , 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5],\n",
       "       [0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = matrix_filled(X)\n",
    "normalized_x = normalize_matrix(x)\n",
    "np.linalg.matrix_power(normalized_x,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 9. Обчислити матрицю Грама для ядерної функції k(x) = xsin(x) + x^2 / 5 \n",
    "на множині X = {1, 0, 7, 6, 4, 10}. Аргумент функції sin(x) задано в радіанах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x):\n",
    "    return x * np.sin(x) + (x ** 2) / 5\n",
    "\n",
    "X = np.array([1,0,7,6,4,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.08,   0.  ,  15.  ,   5.75,   0.18,  15.16],\n",
       "       [  0.  ,   0.  ,   0.  ,   0.  ,   0.  ,   0.  ],\n",
       "       [ 15.  ,   0.  , 207.33,  79.53,   2.49, 209.65],\n",
       "       [  5.75,   0.  ,  79.53,  30.51,   0.95,  80.42],\n",
       "       [  0.18,   0.  ,   2.49,   0.95,   0.03,   2.52],\n",
       "       [ 15.16,   0.  , 209.65,  80.42,   2.52, 211.99]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def form_gram_matrix(X,kernel):\n",
    "    n = X.shape[0]\n",
    "    K = np.array([[kernel(X[i])*kernel(X[j]) for i in range(n)] for j in range(n)])\n",
    "    return K\n",
    "form_gram_matrix(X,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 10. Перевірити, чи є відносить задана ядерна функція k(x) = exp{sin(x) + 1} + xtan(x) до класу ядерних функцій Мерсена. \n",
    "Перевірку виконати на множині X={7, 6, 2, 1, 0, 4, 6, 9}. Аргументи тригонометричних функцій задано в радіанах.\n",
    "\n",
    "Маємо сформувати матрицю грама та перевірити, що вона positive definite. Якщо вона буде вона positive definite, ядерна ф-ція відноситься до класу ядерних ф-й Мерсена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([7,6,2,1,0,4,6,9])\n",
    "def k(x):\n",
    "    return np.exp(np.sin(x)+1) + x*np.tan(x)\n",
    "\n",
    "def form_gram_matrix(X,kernel):\n",
    "    n = X.shape[0]\n",
    "    K = np.array([[kernel(X[i])*kernel(X[j]) for i in range(n)] for j in range(n)])\n",
    "    return K\n",
    "\n",
    "def check_positive_definite(K,X):\n",
    "    return X.T@K@X \n",
    "\n",
    "def check_kernel_function(X,kernel,print_gram=False):\n",
    "    K = form_gram_matrix(X,kernel)\n",
    "    \n",
    "    if print_gram:\n",
    "        print(f'Gram matrix:\\n{K}')\n",
    "    \n",
    "    prod = check_positive_definite(K,X)\n",
    "    print(f'X.T@K@X={prod}')\n",
    "    if prod>0:\n",
    "        return \"kernel function is positive-definite\"\n",
    "    return \"kernel function isn't positive-definite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram matrix:\n",
      "[[128.68   3.51  26.98  89.2   30.84  67.     3.51   0.38]\n",
      " [  3.51   0.1    0.74   2.43   0.84   1.83   0.1    0.01]\n",
      " [ 26.98   0.74   5.66  18.7    6.46  14.05   0.74   0.08]\n",
      " [ 89.2    2.43  18.7   61.83  21.37  46.44   2.43   0.27]\n",
      " [ 30.84   0.84   6.46  21.37   7.39  16.06   0.84   0.09]\n",
      " [ 67.     1.83  14.05  46.44  16.06  34.89   1.83   0.2 ]\n",
      " [  3.51   0.1    0.74   2.43   0.84   1.83   0.1    0.01]\n",
      " [  0.38   0.01   0.08   0.27   0.09   0.2    0.01   0.  ]]\n",
      "X.T@K@X=14321.124233689508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kernel function is positive-definite'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_kernel_function(X,k,print_gram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 11. Перевірити, чи належить задана ядерна функція k(x) = ln(1 + exp(-x) + tg(x)^2) до класу ядерних функцій Мерсена. \n",
    "  Перевірку виконати на множині X={1,9,7,5,3,2}. Аргументи тригонометричних функцій задано в радіанах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,9,7,5,3,2])\n",
    "def k(x):\n",
    "    return np.log(1+np.exp(-x)+np.tan(x)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram matrix:\n",
      "[[1.78 0.25 0.75 3.36 0.09 2.37]\n",
      " [0.25 0.03 0.11 0.47 0.01 0.33]\n",
      " [0.75 0.11 0.32 1.43 0.04 1.  ]\n",
      " [3.36 0.47 1.43 6.35 0.17 4.48]\n",
      " [0.09 0.01 0.04 0.17 0.   0.12]\n",
      " [2.37 0.33 1.   4.48 0.12 3.16]]\n",
      "X.T@K@X=544.14218243972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kernel function is positive-definite'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_kernel_function(X,k,print_gram=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 12. Визначити вектор прихованих факторів (latent variables) за відомою матрицею змішування W та вектором математичного очікування mu. \n",
    "  Розглянути випадок, коли вплив помилок відсутній (eps -> 0)\n",
    "  mu = (4,5,3,6)\n",
    "  W = (1,2,3)\n",
    "    (95,7,0)\n",
    "    (1,2,5)\n",
    "    (0,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18  1.67 -1.67]\n"
     ]
    }
   ],
   "source": [
    "W =np.array([[1,2,3],\n",
    "    [95,7,0],\n",
    "    [1,2,5],\n",
    "    [0,0,1]])\n",
    "mu = np.array([4,5,3,6])\n",
    "z = np.dot(np.linalg.pinv(W),(-mu))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DONE 13. Обчислити перші 3 головні компоненти для заданої вибірки значень:\n",
    "  X = {(1,2,3,8);\n",
    "     (5,3,6,2);\n",
    "     (7,5,6,8);\n",
    "     (0,0,0,1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3,8],\n",
    "     [5,3,6,2],\n",
    "     [7,5,6,8],\n",
    "     [0,0,0,1]])\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "u, s, vh = np.linalg.svd(X, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45103945,  0.74955999,  0.47409566, -0.09978246],\n",
       "       [-0.45211097, -0.64452157,  0.60908097,  0.09595827],\n",
       "       [-0.76864884, -0.06716484, -0.63454343, -0.04497204],\n",
       "       [-0.03657932,  0.13505797, -0.04010375,  0.98934978]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.10171748,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  5.64592816,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.62212023,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[n_components:] = 0\n",
    "np.diag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47317681, -0.35678615, -0.50741554, -0.62556919],\n",
       "       [-0.52129636, -0.13642911, -0.35803476,  0.76252759],\n",
       "       [-0.56857901, -0.24491583,  0.78262522, -0.0650531 ],\n",
       "       [ 0.42552523, -0.8911268 ,  0.04287594,  0.15160132]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.00650628,  1.98637468,  3.00065557,  8.00231798],\n",
       "        [ 4.99374308,  3.01310313,  5.99936955,  1.99777085],\n",
       "        [ 7.00293239,  4.99385906,  6.00029547,  8.00104472],\n",
       "        [-0.06451019,  0.135096  , -0.00650005,  0.97701704]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconst = np.matrix(u) * np.diag(s) * np.matrix(vh)\n",
    "reconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Обчислити антиградіент квадратичної функції втрат в точці x = 0, y = 1:\n",
    "  loss = 1/2 * (y - f(x)) ^2\n",
    "  f(x) = tg(x^2 - 2) + exp(sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tan(x**2-2)+np.exp(np.sin(x))\n",
    "\n",
    "def loss(x,y):\n",
    "    return 0.5*(y-f(x)) **2\n",
    "\n",
    "x,y=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done 15. Вирішити систему лінійних арифметичних рівнянь:\n",
    "    *  2x1 - 2x2 + 8x3 + 12x4 = 0\n",
    "    *  22x2 + 43x4 = 1\n",
    "    *  -3x1 + 7x2 = 4\n",
    "    *  5x2 + 4x4 = 3\n",
    "    *  11x1+12x2-4x3 = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.36  3.02  1.43 -1.53]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[2, -2, 8, 12],\n",
    "              [0, 22 ,0, 43],\n",
    "              [-3, 7 ,0, 0],\n",
    "              [0, 5, 0, 4],\n",
    "              [11, 12, -4, 0]])\n",
    "\n",
    "y = np.array([0, 1, 4, 3, 101])\n",
    "\n",
    "# theta = (X.T * X)^(-1)* X.T * y\n",
    "X = np.matrix(X)\n",
    "theta = np.dot(np.linalg.inv(X.T * X) * X.T, y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деякі задачі протягом триму:\n",
    "\n",
    "#1. До якого з розподілів належать нові дані?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 1.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22062422564614886, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1,p2,p3,p4 = stats.norm.pdf(1.75,0,1),stats.norm.pdf(1.75,3,1.5),stats.norm.pdf(1.75,1.5,2),stats.laplace.pdf(1.75,2,2)\n",
    "probs = [p1,p2,p3,p4]\n",
    "max(probs), probs.index(max(probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Знайти параметри розподілу (MVN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,2,1,3,7])\n",
    "x2 = np.array([2,1,2,4,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.array([x1.mean(),x2.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\sum(x_i-m)(x_i-m)^T}{N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix  = np.cov(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Множимо матриці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Знайти параметри розподілів: вектор середнього та матрицію коваріації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cov_vect(X):\n",
    "    Y = X-X.mean(axis=1,keepdims=True)\n",
    "    matr = np.zeros(X.shape)\n",
    "    for i in range(Y.shape[0]):\n",
    "        col = np.array(Y[:,i],ndmin=2)\n",
    "        rm = np.dot(col.T,col)\n",
    "        matr+=rm   \n",
    "    return matr/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.22222222, 0.33333333],\n",
       "       [0.22222222, 0.22222222, 0.33333333],\n",
       "       [0.33333333, 0.33333333, 0.66666667]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_cov_vect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],\n",
    "     [2,3,4],\n",
    "     [7,7,9],\n",
    "     [0, 11, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 2,  3,  4],\n",
       "       [ 7,  7,  9],\n",
       "       [ 0, 11,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.08466181,   0.        ,  14.99604301,   5.75257229,\n",
       "          0.17995579,  15.16359768],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [ 14.99604301,   0.        , 207.3284995 ,  79.53245929,\n",
       "          2.48798727, 209.6450344 ],\n",
       "       [  5.75257229,   0.        ,  79.53245929,  30.5091297 ,\n",
       "          0.95440688,  80.42109602],\n",
       "       [  0.17995579,   0.        ,   2.48798727,   0.95440688,\n",
       "          0.02985639,   2.5157862 ],\n",
       "       [ 15.16359768,   0.        , 209.6450344 ,  80.42109602,\n",
       "          2.5157862 , 211.98745255]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kernel(x):\n",
    "    return x*np.sin(x)+(x**2)/5\n",
    "\n",
    "X = ([1,0,7,6,4,10])\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        arr[i,j]=kernel(X[i])*kernel(X[j])\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  7,  6,  4, 10]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_distances(X,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "gram = pairwise_distances(X,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tan(x**2-2)+np.exp(np.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.370079726523038"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-f(0))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg(x^2 - 2) + exp(sin(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
